{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'pos_encoding': self.pos_encoding,\n",
    "        \n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        angle_rads = np.zeros(angle_rads.shape)\n",
    "        angle_rads[:, 0::2] = sines\n",
    "        angle_rads[:, 1::2] = cosines\n",
    "        pos_encoding = tf.constant(angle_rads)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 문장의 길이 50, 임베딩 벡터의 차원 128\n",
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "  # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 스케일링\n",
    "  # dk의 루트값으로 나눠준다.\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Query, Key, Value인 Q, K, V 행렬 생성\n",
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)    def get_config(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 함수 실행\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값\n",
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'num_heads' :self.num_heads,\n",
    "            'd_model' :self.d_model,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "      # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, key의 문장 길이)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': padding_mask # 패딩 마스크 사용\n",
    "      })\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 포지셔널 인코딩 + 드롭아웃\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 인코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "  # 룩어헤드 마스크(첫번째 서브층)\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  # 패딩 마스크(두번째 서브층)\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "      })\n",
    "\n",
    "  # 잔차 연결과 층 정규화\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "          'mask': padding_mask # 패딩 마스크\n",
    "      })\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 포지셔널 인코딩 + 드롭아웃\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 디코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "  # 인코더의 입력\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 디코더의 입력\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더의 패딩 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 디코더의 패딩 마스크(두번째 서브층)\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 다음 단어 예측을 위한 출력층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9000, 128)\n",
      "(1, 9000, 128)\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실 함수 정의\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx5klEQVR4nO3deZhcZZ3//fe39+70kqTT2RMSSAI0yNpEcHBFJYxLcAxjoo74E2VG4XFh5nHg54zj8JPfM4gjjooLCspwgQFRx4hoRBABhZCwk0CgSQJJyL50Z+vqru7v88c5lVSKqq7q6jpd3V2f13XVVafuc5/73HW6+3z7Xs455u6IiIgUWlmxKyAiIqOTAoyIiERCAUZERCKhACMiIpFQgBERkUhUFLsCxTRhwgSfNWtWsashIjKiPP744zvdvSVbvpIOMLNmzWLVqlXFroaIyIhiZq/kkk9dZCIiEgkFGBERiYQCjIiIREIBRkREIqEAIyIikYg0wJjZAjNba2btZnZlmvXVZnZHuH6Fmc1KWndVmL7WzM5PSr/ZzLab2XMZ9vmPZuZmNiGSLyUiIjmJLMCYWTlwA3AB0AosMbPWlGyXAHvcfQ5wPXBtuG0rsBg4CVgAfDcsD+AnYVq6fc4A3g28WtAvIyIiAxZlC2Y+0O7u69y9G1gKLEzJsxC4JVy+CzjPzCxMX+ruMXdfD7SH5eHuDwK7M+zzeuCLQFGeQbCts4vfr95ajF2LiAw7UQaYacDGpM+bwrS0edw9DnQAzTluexQzWwhsdvens+S71MxWmdmqHTt25PI9cvbRH63g0lsfJxbvLWi5IiIj0agY5DezOuB/A1/Oltfdb3T3Nndva2nJeqeDAdm05xAAnYfiBS1XRGQkijLAbAZmJH2eHqalzWNmFUATsCvHbZMdB8wGnjazDWH+J8xs8iDqP2C1VcEwUcehnqHcrYjIsBRlgFkJzDWz2WZWRTBovywlzzLg4nB5EXC/B89wXgYsDmeZzQbmAo9l2pG7P+vuE919lrvPIuhSO8Pdh3RApLYyEWC6h3K3IiLDUmQBJhxTuRxYDjwP3Onuq83sajN7f5jtJqDZzNqBK4Arw21XA3cCa4DfAZe5ey+Amf0UeAQ43sw2mdklUX2HgUq0YPYeVAtGRCTSuym7+z3APSlpX05a7gIuyrDtNcA1adKX5LDfWQOtayEkWjAKMCIio2SQf7g4HGA0BiMiogBTSFUVweHsOKgxGBERBZgC6u7tA9SCEREBBZiCisXDAKMxGBERBZhCivUEV/CrBSMiogBTUIkuMo3BiIgowBRUrEdjMCIiCQowBaQxGBGRIxRgCihxF+XOrh56+4ryxAARkWFDAaaAYvE+qivKcIdOdZOJSIlTgCkQd6c73seUphoAdmugX0RKnAJMgSTGX6aOrQVg575YMasjIlJ0CjAFkhpgdh1QC0ZESpsCTIEkBvinJVow+9WCEZHSpgBTIN1hC2ZyUw1msHO/WjAiUtoUYAok0UVWV1XO+LoqtWBEpOQpwBRI4ir+6opymuur2KUAIyIlTgGmQBJjMNWVZUyor2aXushEpMQpwBRIoousuryM5vpqdZGJSMmLNMCY2QIzW2tm7WZ2ZZr11WZ2R7h+hZnNSlp3VZi+1szOT0q/2cy2m9lzKWVdZ2YvmNkzZvZLMxsb5XdLdTjAVJYxob5KLRgRKXmRBRgzKwduAC4AWoElZtaaku0SYI+7zwGuB64Nt20FFgMnAQuA74blAfwkTEt1L3Cyu58CvAhcVdAvlEXiWTDVFeVMqK9mXyxOV5gmIlKKomzBzAfa3X2du3cDS4GFKXkWAreEy3cB55mZhelL3T3m7uuB9rA83P1BYHfqztz99+4eDz8+Ckwv9Bfqz+EWTEUZzWOqAF1sKSKlLcoAMw3YmPR5U5iWNk8YHDqA5hy37c8ngN+mW2Fml5rZKjNbtWPHjgEU2b/u+JFZZC0N1QDs0O1iRKSEjbpBfjP7EhAHbku33t1vdPc2d29raWkp2H6Tx2AmNQY3vNza0VWw8kVERpooA8xmYEbS5+lhWto8ZlYBNAG7ctz2dczs48B7gY+4+5A+kOXwNOWKssN3VN7acWgoqyAiMqxEGWBWAnPNbLaZVREM2i9LybMMuDhcXgTcHwaGZcDicJbZbGAu8Fh/OzOzBcAXgfe7+8ECfo+cxJK6yMaPqaKqvIwtnWrBiEjpiizAhGMqlwPLgeeBO919tZldbWbvD7PdBDSbWTtwBXBluO1q4E5gDfA74DJ37wUws58CjwDHm9kmM7skLOs7QANwr5k9ZWbfj+q7pZO4kr+qogwzY1JTNdvURSYiJawiysLd/R7gnpS0LyctdwEXZdj2GuCaNOlLMuSfM6jKDlIs3ktFmVFeZgBMaaxliwKMiJSwUTfIXyyJxyUnTGqqYau6yESkhCnAFEgs3kt1Zfnhz1Oaatja0cUQzzUQERk2FGAKJNaT0oJprCEW72PvwZ4i1kpEpHgUYAqku/foAHN4qrK6yUSkRCnAFEjQgjnSRTa5SRdbikhpU4ApkGAM5sjhnNpUC8DmvbrYUkRKkwJMgaTOIpvYUE1VeRkb9wz5NZ8iIsOCAkyBxOJ9VCUFmLIyY/q4WjbuVoARkdKkAFMgsXjvUWMwADPG17Fxt7rIRKQ0KcAUSOo0ZYAZ42t5VS0YESlRCjAFkjoGAzBzfB0dh3roOKRrYUSk9CjAFEh3vO/1XWTj6gA0DiMiJUkBpkBSpylDMAYDsEkzyUSkBCnAFEi6LrJEgNE4jIiUIgWYAoml6SJrqq2ksaZCAUZESpICTAHEe/vo7fPXtWAAZrfUs2GnAoyIlB4FmAJIPC65Kk2AOa5lDO3b9w91lUREik4BpgASASZdC+a4lnq2dnaxPxYf6mqJiBSVAkwBxOK9AEc9cCzhuJZ6ANbtUCtGREpLpAHGzBaY2VozazezK9OsrzazO8L1K8xsVtK6q8L0tWZ2flL6zWa23cyeSylrvJnda2Yvhe/jovxuyWI9mVswcyaOAeBlBRgRKTGRBRgzKwduAC4AWoElZtaaku0SYI+7zwGuB64Nt20FFgMnAQuA74blAfwkTEt1JXCfu88F7gs/D4nu3kSAeX0L5pjmMVSUGS9vPzBU1RERGRaibMHMB9rdfZ27dwNLgYUpeRYCt4TLdwHnmZmF6UvdPebu64H2sDzc/UFgd5r9JZd1C3BhAb9Lv/prwVSWlzGzuU4tGBEpOVEGmGnAxqTPm8K0tHncPQ50AM05bptqkrtvCZe3ApPSZTKzS81slZmt2rFjRy7fI6sjYzDpD+dxLfUKMCJSckblIL+7O+AZ1t3o7m3u3tbS0lKQ/R2ZRfb6LjKAORPrWb/zAN1hPhGRUhBlgNkMzEj6PD1MS5vHzCqAJmBXjtum2mZmU8KypgDb8675ACVaMOmugwE4cUojPb2uVoyIlJQoA8xKYK6ZzTazKoJB+2UpeZYBF4fLi4D7w9bHMmBxOMtsNjAXeCzL/pLLuhj4VQG+Q076G4MBaJ3SAMCa1zqHqkoiIkUXWYAJx1QuB5YDzwN3uvtqM7vazN4fZrsJaDazduAKwplf7r4auBNYA/wOuMzdewHM7KfAI8DxZrbJzC4Jy/oP4F1m9hLwzvDzkOjvQkuA2RPqqaksY80WBRgRKR0VURbu7vcA96SkfTlpuQu4KMO21wDXpElfkiH/LuC8wdQ3X/1daAlQXmYcP6mB5xVgRKSEjMpB/qHWnaUFA9A6tZE1WzoJegBFREY/BZgCyNZFBsFA/96DPWzp6BqqaomIFJUCTAFkm6YM0DqlEdBAv4iUDgWYAoj19GIGleWWMU/r1EbKDJ7etHfoKiYiUkQKMAWQeFxycJeb9OqqKjhhciNPvrp36ComIlJEWQOMmc0zs/sSdy82s1PM7F+ir9rIEYv3UVWePVafPnMsT2/cS1+fBvpFZPTLpQXzQ+AqoAfA3Z8huGhSQrF4b8YpyslOnzmOfbG4rugXkZKQS4Cpc/fUq+j1eMYksZ6+fmeQJZw+cyyAuslEpCTkEmB2mtlxhDePNLNFwJb+NyktiTGYbGY3j6GxpoInN+4ZglqJiBRXLlfyXwbcCJxgZpuB9cBHIq3VCBMEmOxdZGVlxmkzx/H4KwowIjL65dKCcXd/J9ACnODu5+a4XckIxmByOyRvnD2eF7ftZ9f+WMS1EhEprlzOij8HcPcD7r4vTLsruiqNPLl2kQGcc1wzAI+uS/dQThGR0SNjF5mZnQCcBDSZ2d8krWoEaqKu2EgSi/cxtrYyp7xvmNbEmKpyHlm3k/ecMiXimomIFE9/YzDHA+8FxgLvS0rfB3wqwjqNOLGeXqoaqnPKW1lexvzZ4/nLy7sirpWISHFlDDDu/ivgV2Z2jrs/MoR1GnG6B9BFBkE32R/X7mBbZxeTGtUYFJHRKZdZZE+a2WUE3WWHz4bu/onIajXC5DqLLOGcYycA8MjLu7jw9GlRVUtEpKhy+bf7VmAycD7wJ2A6QTeZhAYyiwyCG182j6nigbXbI6yViEhx5XJWnOPu/woccPdbgPcAb4y2WiPLQGaRQfCEy7ce38IDL+6gV/clE5FRKpezYk/4vtfMTgaagInRVWnkGWgXGcB5J0xi78EennxVF12KyOiUS4C50czGAf8CLAPWANdGWqsRxN0HPMgP8OZ5E6goM+57Qd1kIjI6ZT0ruvuP3H2Puz/o7se6+0Tgt7kUbmYLzGytmbWb2ZVp1leb2R3h+hVmNitp3VVh+lozOz9bmWZ2npk9YWZPmdnDZjYnlzoO1uGnWQ5gDAagsaaSs2aN5/7nFWBEZHTq96xoZueY2SIzmxh+PsXMbgf+nK1gMysHbgAuAFqBJWbWmpLtEmCPu88BridsGYX5FhPMXFsAfNfMyrOU+T3gI+5+GnA7QYsrcrk8LjmT806cyNpt+3h118FCV0tEpOgyBhgzuw64Gfgg8Bsz+yrwe2AFMDeHsucD7e6+zt27gaXAwpQ8C4FbwuW7gPMseCzkQmCpu8fcfT3QHpbXX5lOcJcBCMaJXsuhjoMWi/cCUDXALjKABSdPBuDuZ4ekqiIiQ6q/62DeA5zu7l3hGMxG4GR335Bj2dPCbRI28frZZ4fzuHvczDqA5jD90ZRtExeMZCrzk8A9ZnYI6ATOTlcpM7sUuBRg5syZOX6VzGI9iRbMwAPM9HF1nD5zLHc/vYXPvG1IevRERIZMf2fFLnfvAnD3PcBLAwguxfAF4K/dfTrwY+Ab6TK5+43u3ububS0tLYPe6ZEusvxuMP3eU6ayZkunnnIpIqNOf2fFY81sWeIFzE75nM1mYEbS5+lhWto8ZlZB0LW1q59t06abWQtwqruvCNPvAN6UQx0HLdFFls8YDMB73jAFM7j7aT3DTURGl/66yFLHS/5zgGWvBOaa2WyCwLAY+HBKnmXAxcAjwCLgfnf3MIDdbmbfAKYSjPk8BliGMvcQ3PV5nru/CLwLeH6A9c1Ld56zyBImN9Vw1qzxLHt6M589bw7BEJSIyMjX380u/zSYgsMxlcuB5UA5cLO7rzazq4FV7r4MuAm41czagd0EAYMw350E19zEgcvcvRcgXZlh+qeAn5tZH0HAGZJ7pQ22iwzgg2dM459//ixPvLqXM48ZV6iqiYgUVS43u8ybu98D3JOS9uWk5S7gogzbXgNck0uZYfovgV8OssoDNphpygnvPWUqV/96DXesfFUBRkRGDT36eJBiPYkxmPwP5ZjqCt536lR+/fQW9nX1ZN9ARGQEUIAZpEJ0kQF86KwZHOrp5e5nNNgvIqND1i4yM/s1wUWMyTqAVcAPElOZS1UhusgATpsxlhMmN3DrI6+w+KwZGuwXkREvl3+71wH7gR+Gr06C58HMCz+XtMPTlPOcRZZgZnz8TbNYs6WTR9ftLkTVRESKKpez4pvc/cPu/uvw9VHgLHe/DDgj4voNe4O5kj/VhadPY/yYKm56eP2gyxIRKbZczor1Znb4nirhcn34sTuSWo0g3b2F6SIDqKks56NnH8N9L2xjna7sF5ERLpcA84/Aw2b2RzN7AHgI+CczG8ORG1WWrEQLJp+bXabzd2cfQ2VZGT9SK0ZERrisg/zufo+ZzQVOCJPWJg3sfzOqio0UsXgvleVGeVlhBuVbGqq5qG06d67ayGfedhzTx9UVpFwRkaGW67/dZxI8m+VU4G/N7GPRVWlkyedxydlc9vY5GMYNf3y5oOWKiAylrAHGzG4Fvg6cC5wVvtoirteIEYv3FmSAP9nUsbV86KwZ/GzVRjbu1sPIRGRkyuVWMW1Aq7unXgsjBGMwhRp/SfaZtx/HHSs38q37XuK6i04tePkiIlHL5cz4HDA56oqMVEEXWeEDzJSmWv7unGO464lNrH6to+Dli4hELZcz4wRgjZktH+DzYEpC0EVW2DGYhM++Yy5jayu5+tdrUANSREaaXLrIvhJ1JUayWLxv0FfxZ9JUV8kV75rHv/5qNctXb2PByWpIisjIkcs05UE9F2a0646oiyxhyfyZ/Pcjr3DNPWt467wWaquiaS2JiBRaxjOjmT0cvu8zs86k1z4z6xy6Kg5vUUxTTlZRXsb/ufBkNu4+xPV/eDGy/YiIFFrGAOPu54bvDe7emPRqcPfGoavi8BbFNOVUZx/bzJL5M/nRQ+t4ZtPeSPclIlIoOZ0ZzazczKaa2czEK+qKjRSxnujGYJJdecEJTKiv5ot3PUN3+IgAEZHhLJcLLf8fYBtwL/Cb8HV3xPUaMWLxPqrKow8wTbWVfPXCk3lh6z6+ca+6ykRk+MvlzPg54Hh3P8nd3xC+TsmlcDNbYGZrzazdzK5Ms77azO4I168ws1lJ664K09ea2fnZyrTANWb2opk9b2afzaWOgxXlNOVU7z5pMkvmz+AHD77Mn9t3Dsk+RUTylUuA2UjwBMsBMbNy4AbgAqAVWGJmrSnZLgH2uPsc4Hrg2nDbVmAxwf3PFgDfDbvp+ivz48AM4AR3PxFYOtA65yPKacrp/Ot7Wzl2whi+cMdT7D5Q8k9LEJFhLNcnWj4QtiiuSLxy2G4+0O7u69y9m+CEvzAlz0KO3PL/LuA8C54VvBBY6u4xd18PtIfl9Vfmp4Gr3b0PwN2351DHQYv1RDtNOVVdVQXfXnIGew/28LmlT9LbpwswRWR4yuXM+CrB+EsV0JD0ymYaQesnYVOYljaPu8cJWkrN/WzbX5nHAR8ys1Vm9tvwEQOvY2aXhnlW7dixI4ev0b/u3minKafTOrWRqxeexEMv7eRrv3thSPctIpKrfi+0DLuk5rn7R4aoPoNRDXS5e5uZ/Q1wM/Dm1EzufiNwI0BbW9ug/v2P9/bR2+dD2oJJWDx/Jqtf6+QHD67jxCmNXHh6auwWESmufs+M7t4LHGNmVXmUvZlgTCRhepiWNo+ZVQBNwK5+tu2vzE3AL8LlXwI5TUQYjFg4XXgox2CSffl9rcyfPZ5//vkzPP7K7qLUQUQkk1zHYP5sZv86wDGYlcBcM5sdBqjFQOpNMpcBF4fLi4D7w8cCLAMWh7PMZgNzgceylPk/wNvD5bcCkc/lPRxghriLLKGyvIzvfeQMpjTV8ImfrOKlbfuKUg8RkXRyCTAvE1z3UsYAxmDCMZXLgeXA88Cd7r7azK42s/eH2W4Cms2sHbgCuDLcdjVwJ7AG+B1wmbv3ZiozLOs/gA+a2bPA/wd8MofvNiixeC9AUbrIEprrq7n1kjdSVVHGx25+jNf2HipaXUREklkp3wa+ra3NV61alff2G3Ye4G1ff4Bv/O2p/M0Z0wtYs4Fb81onH/rBI7Q0VrP0U2czsbGmqPURkdHLzB5396xPNs7lSv4WM7vOzO4xs/sTr8JUc2QrdhdZstapjdz8v85ia0cXi298lG2dXcWukoiUuFz6dm4DXgBmA/8ObCAYCyl5w6GLLNlZs8bz35+Yz7bOIMhs7VCQEZHiyeXM2OzuNwE97v4nd/8E8I6I6zUiFHsWWTpts8bz35e8kR37Ynzwe3+hffv+YldJREpULmfGnvB9i5m9x8xOB8ZHWKcRo3sYdZElO/OYcfz0U2cTi/ey6Pt/YdUGTWEWkaGXS4D5qpk1Af8I/BPwI+ALkdZqhBhuXWTJ3jC9iV98+q8YV1fFh3+0gt8+u6XYVRKREpP1zOjud7t7h7s/5+5vd/cz3T31epaSFOsZfl1kyWY21/HzT7+Jk6c28unbnuA/f7+WPt27TESGSC6zyOaZ2X1m9lz4+RQz+5foqzb8DadZZJmMH1PF7Z86m79tm86372/nkltW0nGoJ/uGIiKDlMu/3j8EriIci3H3ZwiuoC95iS6yqmHYRZasprKcaz94Cl+98GQebt/J+779ME9t3FvsaonIKJfLmbHO3R9LSYtHUZmR5kgLZngHGAAz46NnH8PSS8+mt89Z9L2/cMMf23W7fxGJTC5nxp1mdhzgAGa2CNCIMUljMCMgwCScecx47vncm1lw8mSuW76WD//wUTbtOVjsaonIKJTLmfEy4AfACWa2Gfg88A9RVmqkODKLbPiOwaTTVFvJt5ecztcvOpXnNnfw7usf5Md/Xq/WjIgUVC6zyNa5+zuBFoLHEZ8LfCDymo0A3fE+zKCy3IpdlQEzMxadOZ3fX/FW5s8ez7//eg2Lvv8XXtQdmUWkQHLu23H3A+6eOPvkcrv+US8WDx6XHDzleWSaNraWH3/8LL75odPYsPMA7/nWQ/zfe55nX5dmmonI4OQ7eDByz6gFFASYkdU9lo6ZceHp0/jDFW/lwtOm8cOH1vH2rz/AnSs36roZEclbvgFGZx2CMZiRNMCfTXN9NddddCq/uuyvOKZ5DF/8+TO8/4aHefDFHZTyYx1EJD8Zz45mts/MOtO89gFTh7COw1asp2/YXsU/GKdMH8td/3AO/7X4NPYc6OFjNz/Gh258lJW6p5mIDEBFphXunvWplaUuFu+jqnz0BRgIus0WnjaNBSdPZuljG/nOH9u56PuP8NZ5LXzhXfM4bcbYYldRRIa50Xl2HCJBF9nIH4PpT3VFORe/aRYP/r9v56oLTuDpTXu58IY/s/jGR3hg7XZ1nYlIRgowgxCLj84usnRqq8r5+7cex8P//A7+5T0nsmHnQT7+45Vc8F8P8T9Pbqant6/YVRSRYSbSs6OZLTCztWbWbmZXpllfbWZ3hOtXmNmspHVXhelrzez8AZT5LTMbkqdsJaYpl5L66go++eZjefCLb+frF51Kb5/z+Tue4txr7+ebf3iR7XpUs4iEIjs7mlk5cANwAdAKLDGz1pRslwB73H0OcD1wbbhtK8ENNU8CFgDfNbPybGWaWRswLqrvlGq0TFPOR1VFGYvOnM7yz7+Fmz/exgmTG/nmH17iTf9xP5fd/gSPrtul7jOREpdxkL8A5gPt7r4OwMyWAguBNUl5FgJfCZfvAr5jwVWLC4Gl7h4D1ptZe1gemcoMg891wIcZojsNxHp6qW6oHopdDVtlZcY7TpjEO06YxIadB7htxSvcuWoTv3lmC7MnjGHRmdP5wOnTmDq2tthVFZEhFmX/zjRgY9LnTWFa2jzuHgc6gOZ+tu2vzMuBZe7e7404zexSM1tlZqt27NgxoC+UqjveR3VlabZg0pk1YQxfek8rj151HtctOoWJDdVct3wtf3Xt/Xz0Ryv4nyc3c6i7t9jVFJEhEmULZsiY2VTgIuBt2fK6+43AjQBtbW2D6sMpxTGYXNRWlXNR2wwuapvBq7sO8vMnNvHzJzbx+TueoraynPNOnMh7T5nC246fSI0CtMioFWWA2QzMSPo8PUxLl2eTmVUATcCuLNumSz8dmAO0h/cFqzOz9nBsJzKxeO+wf9hYsc1sruML75rH586by4r1u7n7mdf47XNbufuZLYypKuedrZN4zxum8JZ5LQo2IqNMlAFmJTDXzGYTBIHFBOMjyZYBFwOPAIuA+93dzWwZcLuZfYPgrgFzgccI7oH2ujLdfTUwOVGome2POrhAeCW/AkxOysqMc45r5pzjmvn395/Eo+t285tng2Dzq6deo7aynHPnTuBdJ07i7SdMpKXEx7ZERoPIAoy7x83scmA5UA7c7O6rzexqYJW7LwNuAm4NB/F3Ez6KOcx3J8GEgDhwmbv3AqQrM6rvkE0pzyIbjIryMs6dO4Fz507g6oUn88jLu/jD89v4w5pt3LtmG2Zw2oyxvPPESbzt+BZOnNxIWZnuryoy0lgpTyVta2vzVatW5bVtX59z7P++h8+dN5cvvGtegWtWmtydNVs6ue/57fzh+W08s6kDgAn1VfzVnAmcO2cCb57bwuSmmiLXVKS0mdnj7t6WLd+oGOQvhu7wyvVSuZJ/KJgZJ01t4qSpTXz2vLls6+zioZd28vBLO3i4fSe/euo1AOZOrA9aQHMm0HbMeJrqKotccxFJRwEmT7F4GGDURRaZSY01LDpzOovOnE5fn/PC1n083L6Dh17aye0rXuXHf96AGRw/qYE3zh7PWbPHM3/WeCY2qoUjMhwowOQpFg+u59Ag/9AoKzNapzbSOrWRS99yHF09vTz56l5WbtjNY+t387PHN3HLI68AMKu5jrNmBQHn9BljOa6lXmM4IkWgAJOnWE+iBaMAUww1leWHZ6UB9PT2sfq1Tlau382K9bu59/lt/OzxTQA0VFdwyowmTp0+ltNmjOW0mWOZ2KBWjkjUFGDylOgi03Uww0NleVkQPGaM5VNvOZa+PuflHft5auNentq4l6c37eXGB9cRDx8BPbWphtNmjg3HfBo5aWqTpkaLFJgCTJ6OdJFpDGY4Kisz5k5qYO6kBi5qC67N7erp5bnNHUcFnXue3Xp4m5aG6jDYBAGndUojM8fXqXtNJE8KMHk6PMivWWQjRk1lOW2zxtM2a/zhtI5DPax5rZPVr3WwZksna17r5KGXdtIbtnTqqyuYN6meeWGwOn5SA/Mm1dPSUE141wgRyUABJk8agxkdmmorjxrLgaCl89K2/YeDztqt+1i+eitLV248art5k+qZO6mBeRPrmTe5gXmTGphQr242kQQFmDwdvg5GXWSjTk1lOW+Y3sQbpjcdTnN3du7v5qVt+3hx2z5e3L6fl7bt4zfPbOH2Qz2H8zXVVjJ7whiOnTCG2RPGMLtlDLOag+Ux1fpzk9Ki3/g8xXo0TbmUmBktDdW0NFTzpjkTDqe7Ozv2xVi7bR8vbtvP+p37Wb/zAI+u28Uvnjz63q6TGquDoDOhntkT6pg9oZ5ZzXVMH1dHbZX+UZHRRwEmT4kxmBqNwZQ0M2NiYw0TG2t489yWo9Yd6u5lw64DbNh5gHU7D7A+fC1fvZXdB7qPytvSUM2McbXMGF/HjHF1zBhfG77XMaWphopy/Z7JyKMAkyddyS/Z1FaVc+KURk6c0vi6dR0He1i3cz+v7j7Ixt0H2bj7EBv3HOTxV/Zw9zNbDk8yACgvM6aOrQkCThh8pjTVMmVsDVObapncVKNHHciwpACTJ13JL4PRVFfJ6TPHcfrMca9bF+/tY0tHVxB49hwJPq/uPsh9L2xn5/7Y67YZP6aKKU01TGmqZerYGiY3BcFnSlMNU8fWMqmxRtdsyZBTgMlTYhaZ/mil0CrKy4KusvF1add39fSypaOLLXsPBe8dh3gt/Lxpz0FWbthNR9LEAwAzmFBfHQahIBBNbKympb466OJrqGZiQzXj6qp03Y8UjAJMntRFJsVSU1keThYYkzHPgVj8cPAJgtGRQLR+5wH+8vIu9nXFX7ddRZkxob46KfhU09IQBKCWMAhNbKyhpb5a/1xJVgoweUp0kemPTIajMdUVzJlYz5yJ9RnzHOruZce+GNv3dbF9X+zIcmeM7ftibOno4ulNHew6ECPdY6PG1lUysaGaCfXVjB9TRfOYKprD5Qn1VYwfc2S5saZSLaMSpACTp1i8j8pyo1x/NDJC1VaVM7O5jpnN6bviEuK9few60P26AJT4vGt/N6tf62TX/hidaVpFEExUSASh8WEgOrJ8dHAaW1tJU22lZs6NAgoweerW45KlRFSUlzGpsYZJjTVAU795u+N97DnYza793ew6EGP3gW527u9m91HL3Ty7aS+7DnSn7aZLaKipYGxdJWNrq4L3uiD4jKurpCmxPKaSpsR6BaZhRwEmT7F4r2aQiaSoqkgORtnF4r3sOdDDrgMxdoXBZ+/BbvYe6mHvwZ6jljftOcSeg910HOpJ22WXkAhM4+qqaKpNH5jG1lXSUFNJY21F8F5TwZiqCnXjFVikAcbMFgD/BZQDP3L3/0hZXw38N3AmsAv4kLtvCNddBVwC9AKfdffl/ZVpZrcBbUAP8Bjw9+5+9FSaAor19CnAiAxSdUU5k5vKmdyU+/N5+vqcfV1x9hwOPkHQ2XNgcIHJLHh2UBB4KmmoqaAxDD7Jnxv6+axejaNFFmDMrBy4AXgXsAlYaWbL3H1NUrZLgD3uPsfMFgPXAh8ys1ZgMXASMBX4g5nNC7fJVOZtwEfDPLcDnwS+F9X3i8X7qNbFbSJDrqzMaKqrpKmuckDbJQLT3kPd7D3Yw76uOJ1dPezr6qHzUDx4D9M6DwXvm/ce4vlDQZ59sXi/AQqC6+JSW0b11RWMqQ7ejyyXvy5tTHUFDTXBe11l+ahoTUXZgpkPtLv7OgAzWwosBJIDzELgK+HyXcB3LLgH+kJgqbvHgPVm1h6WR6Yy3f2eRKFm9hgwPaovBkHTvkp9vSIjRnJgOqY5e/5UfX3Oge44nV3xlKAUBqtDPUet6wwD1paOLg7E4uyPxTkQi9OXJUhB0JqqqyynvuZIcBpTVUH94YAVBKiGpOB0dAAL81RVUFddTlV5WVEeLxFlgJkGbEz6vAl4Y6Y87h43sw6gOUx/NGXbaeFyv2WaWSXwd8DnBln/fgUtGAUYkVJRVmY01ARjN1CbVxnuzqGe3jDY9HIgFmdfVxB4DnQHQWh/+Hl/uH5/UnDauPvg4eUDsd7Dd3XPpqLMqKsKglLi/d/e18qZx4zPvvEgjMZB/u8CD7r7Q+lWmtmlwKUAM2fOzHsnGoMRkYEyM+qqKqirqoCGwZcXi/ceDlSJwLMvfD8Y6+VAd5yD3cH6o96740MyXhRlgNkMzEj6PD1MS5dnk5lVEMyB3JVl24xlmtm/AS3A32eqlLvfCNwI0NbWlkNjNb1YvDf4JRERKZLqinKqK8oZP6aq2FVJK8p/wVcCc81stplVEQzaL0vJswy4OFxeBNzv7h6mLzazajObDcwlmBmWsUwz+yRwPrDE3XNrNw5Cd69aMCIi/YnsX/BwTOVyYDnBlOKb3X21mV0NrHL3ZcBNwK3hIP5ugoBBmO9OggkBceAyd+8FSFdmuMvvA68Aj4SDWb9w96uj+n6xHo3BiIj0J9I+nnBm1z0paV9OWu4CLsqw7TXANbmUGaYPaX9VTFfyi4j0S/+C50lX8ouI9E9nyDwFLRgdPhGRTHSGzFOsp0+36hcR6YfOkHlw97CLTGMwIiKZKMDkId7n9DnqIhMR6YfOkHk4/LhkTVMWEclIZ8g8dCcCjLrIREQyUoDJQyzeC6iLTESkPzpD5iHWoy4yEZFsdIbMQ0xdZCIiWSnA5CHRRaYHjomIZKYzZB40i0xEJDudIfNweAxGXWQiIhkpwORBs8hERLLTGTIP3eoiExHJSmfIPGgWmYhIdgoweVAXmYhIdjpD5uFIC0aHT0QkE50h83DkSn51kYmIZKIAkwddaCkikl2kZ0gzW2Bma82s3cyuTLO+2szuCNevMLNZSeuuCtPXmtn52co0s9lhGe1hmVVRfa9YvA8zqCy3qHYhIjLiRRZgzKwcuAG4AGgFlphZa0q2S4A97j4HuB64Nty2FVgMnAQsAL5rZuVZyrwWuD4sa09YdiRi8T6qK8owU4AREckkyhbMfKDd3de5ezewFFiYkmchcEu4fBdwngVn7YXAUnePuft6oD0sL22Z4TbvCMsgLPPCqL5YrEePSxYRyaYiwrKnARuTPm8C3pgpj7vHzawDaA7TH03Zdlq4nK7MZmCvu8fT5D+KmV0KXAowc+bMgX2j0IlTGjnU05vXtiIipaLkRqnd/UZ3b3P3tpaWlrzKWDx/Jl9bdGqBayYiMrpEGWA2AzOSPk8P09LmMbMKoAnY1c+2mdJ3AWPDMjLtS0REhlCUAWYlMDec3VVFMGi/LCXPMuDicHkRcL+7e5i+OJxlNhuYCzyWqcxwmz+GZRCW+asIv5uIiGQR2RhMOKZyObAcKAdudvfVZnY1sMrdlwE3AbeaWTuwmyBgEOa7E1gDxIHL3L0XIF2Z4S7/GVhqZl8FngzLFhGRIrHgn//S1NbW5qtWrSp2NURERhQze9zd27LlK7lBfhERGRoKMCIiEgkFGBERiYQCjIiIRKKkB/nNbAfwSp6bTwB2FrA6haJ6DYzqNTCq18AM13rB4Op2jLtnvVK9pAPMYJjZqlxmUQw11WtgVK+BUb0GZrjWC4ambuoiExGRSCjAiIhIJBRg8ndjsSuQgeo1MKrXwKheAzNc6wVDUDeNwYiISCTUghERkUgowIiISDTcXa8BvoAFwFqCRzlfGUH5MwgeP7AGWA18Lkz/CsFzbp4KX3+dtM1VYX3WAudnqyswG1gRpt8BVOVYtw3As+H+V4Vp44F7gZfC93FhugHfCvfxDHBGUjkXh/lfAi5OSj8zLL893NZyqNPxScfkKaAT+HyxjhdwM7AdeC4pLfJjlGkfWep1HfBCuO9fAmPD9FnAoaRj9/1899/fd+ynXpH/7IDq8HN7uH5WDvW6I6lOG4CnhvJ4kfncUPTfr7R/C4U+OY72F8FjAl4GjgWqgKeB1gLvY0riFwFoAF4EWsM/un9Kk781rEd1+Mf0cljPjHUF7gQWh8vfBz6dY902ABNS0r5G+AcNXAlcGy7/NfDb8Jf8bGBF0i/quvB9XLic+IN4LMxr4bYX5PHz2QocU6zjBbwFOIOjT0yRH6NM+8hSr3cDFeHytUn1mpWcL6WcAe0/03fMUq/If3bAZwgDAcGjQu7IVq+U9f8JfHkojxeZzw1F//1K+90HevIr9RdwDrA86fNVwFUR7/NXwLv6+aM7qg4Ez8s5J1Ndw1+cnRw5sRyVL0tdNvD6ALMWmBIuTwHWhss/AJak5gOWAD9ISv9BmDYFeCEp/ah8Odbv3cCfw+WiHS9STjhDcYwy7aO/eqWs+wBwW3/58tl/pu+Y5XhF/rNLbBsuV4T5rL96JaUbsBGYW4zjlbQucW4YFr9fqS+NwQzcNIJfrIRNYVokzGwWcDpBEx7gcjN7xsxuNrNxWeqUKb0Z2Ovu8ZT0XDjwezN73MwuDdMmufuWcHkrMCnPek0Ll1PTB2Ix8NOkz8U+XglDcYwy7SNXnyD4jzVhtpk9aWZ/MrM3J9V3oPvP928m6p/d4W3C9R1h/ly8Gdjm7i8lpQ3p8Uo5NwzL3y8FmGHMzOqBnwOfd/dO4HvAccBpwBaCJvpQO9fdzwAuAC4zs7ckr/Tg3xsvQr0IH6P9fuBnYdJwOF6vMxTHaKD7MLMvETw99rYwaQsw091PB64Abjezxqj2n8aw/NklWcLR/8gM6fFKc27Iu6x85LoPBZiB20ww0JYwPUwrKDOrJPgFus3dfwHg7tvcvdfd+4AfAvOz1ClT+i5grJlVpKRn5e6bw/ftBIPC84FtZjYlrPcUgoHRfOq1OVxOTc/VBcAT7r4trGPRj1eSoThGmfbRLzP7OPBe4CPhiQN3j7n7rnD5cYLxjXl57n/AfzND9LM7vE24vinM368w798QDPgn6jtkxyvduSGPsobk90sBZuBWAnPNbHb4H/NiYFkhd2BmBtwEPO/u30hKn5KU7QPAc+HyMmCxmVWb2WxgLsFAXdq6hieRPwKLwu0vJujLzVavMWbWkFgmGO94Ltz/xWnKWgZ8zAJnAx1hE3s58G4zGxd2fbyboF98C9BpZmeHx+BjudQryVH/VRb7eKUYimOUaR8ZmdkC4IvA+939YFJ6i5mVh8vHEhyjdXnuP9N37K9eQ/GzS67vIuD+RIDN4p0E4xSHu5KG6nhlOjfkUdaQ/H4VdDC6VF4EMzNeJPgv5UsRlH8uQfPzGZKmaQK3EkwffCb8YU9J2uZLYX3WkjTzKlNdCWbbPEYwFfFnQHUO9TqWYHbO0wRTJL8UpjcD9xFMX/wDMD5MN+CGcN/PAm1JZX0i3Hc78L+S0tsITiYvA98hh2nK4XZjCP77bEpKK8rxIghyW4Aegj7sS4biGGXaR5Z6tRP0xSd+zxKzqj4Y/oyfAp4A3pfv/vv7jv3UK/KfHVATfm4P1x+brV5h+k+Af0jJOyTHi8znhqL/fqV76VYxIiISCXWRiYhIJBRgREQkEgowIiISCQUYERGJhAKMiIhEQgFGZIDMrNnMngpfW81sc9LnqizbtpnZtwa4v0+Y2bMW3DblOTNbGKZ/3MymDua7iERJ05RFBsHMvgLsd/evJ6VV+JF7Xw22/OnAnwjuoNsR3iKkxd3Xm9kDBDeEXFWIfYkUmlowIgVgZj8xs++b2Qrga2Y238weseDmh38xs+PDfG8zs7vD5a9YcCPHB8xsnZl9Nk3RE4F9wH4Ad98fBpdFBBfE3Ra2nGrN7EwLbrT4uJkttyO39XjAzP4rzPecmc1Psx+RglOAESmc6cCb3P0Kgod4vdmDmx9+Gfi/GbY5ATif4F5b/2bBfaaSPQ1sA9ab2Y/N7H0A7n4XsIrg/mGnEdyo8tvAInc/k+BhWdcklVMX5vtMuE4kchXZs4hIjn7m7r3hchNwi5nNJbi1R2rgSPiNu8eAmJltJ7gF+uF7XLl7b3i/sLOA84DrzexMd/9KSjnHAycD9wa3kKKc4DYnCT8Ny3vQzBrNbKy7783/q4pkpwAjUjgHkpb/D/BHd/+ABc/teCDDNrGk5V7S/E16MFD6GPCYmd0L/JjggVzJDFjt7udk2E/qYKsGXyVy6iITiUYTR25z/vF8CzGzqWZ2RlLSacAr4fI+gsfmQnDjxxYzOyfcrtLMTkra7kNh+rkEd9TtyLdOIrlSC0YkGl8j6CL7F+A3gyinEvh6OB25C9gB/EO47ifA983sEMGjgBcB3zKzJoK/7W8S3OEXoMvMngzL+8Qg6iOSM01TFhnlNJ1ZikVdZCIiEgm1YEREJBJqwYiISCQUYEREJBIKMCIiEgkFGBERiYQCjIiIROL/Bw+GxAaLg8ncAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#학습률\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "  \n",
    "    def get_config(self):\n",
    "        config={\n",
    "            'd_model' :self.d_model,\n",
    "            'warmup_steps' :self.warmup_steps,\n",
    "        }\n",
    "        return config \n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/lib/python3.8/dist-packages\n",
      "sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/lib/python3.8/dist-packages\n",
      "sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/include/python3.8/UNKNOWN\n",
      "sysconfig: /usr/include/python3.8/UNKNOWN\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/bin\n",
      "sysconfig: /usr/bin\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local\n",
      "sysconfig: /usr\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/lib/python3.8/dist-packages\n",
      "sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/lib/python3.8/dist-packages\n",
      "sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/include/python3.8/UNKNOWN\n",
      "sysconfig: /usr/include/python3.8/UNKNOWN\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/bin\n",
      "sysconfig: /usr/bin\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local\n",
      "sysconfig: /usr\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install -q tfds-nightly tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 926\n",
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n",
      "['가리비 구이의 칼로리는 몇이야 ?', '가리비의 칼로리는 몇이야 ?', '가쓰오부시의 칼로리는 몇이야 ?', '가오리의 칼로리는 몇이야 ?', '가자미/넙치 요리의 칼로리는 몇이야 ?']\n",
      "['(1개)당 - 칼로리: 17kcal | 지방: 0 . 50g | 탄수화물: 0 . 38g | 단백질: 2 . 63g', '(1개)당 - 칼로리: 35kcal | 지방: 1 . 75g | 탄수화물: 1 . 68g | 단백질: 2 . 90g', '(100g)  당 - 칼로리: 340kcal | 지방: 2 . 26g | 탄수화물: 2 . 34g | 단백질: 76 . 80g', '(100g)  당 - 칼로리: 84kcal | 지방: 0 . 88g | 탄수화물: 0 . 17g | 단백질: 17 . 60g', '(100g)  당 - 칼로리: 133kcal | 지방: 4 . 24g | 탄수화물: 0 . 41g | 단백질: 22 . 00g']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "# train_data = pd.read_csv('ChatBotData.csv')\n",
    "# train_data.head()\n",
    "DATA_IN_PATH='ChatBotData.csv'\n",
    "train_data=pd.read_csv(DATA_IN_PATH,encoding='utf-8')\n",
    "print('챗봇 샘플의 개수 :', len(train_data))\n",
    "print(train_data.isnull().sum())\n",
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", str(sentence))\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)\n",
    "\n",
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [2067]\n",
      "종료 토큰 번호 : [2068]\n",
      "단어 집합의 크기 : 2069\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임의의 질문 샘플을 정수 인코딩 : [1538, 6, 9, 11]\n",
      "정수 인코딩 후의 문장 [1538, 6, 9, 11]\n",
      "기존 문장: 갈치조림의 칼로리는 몇이야 ?\n",
      "1538 ----> 갈치조림의 \n",
      "6 ----> 칼로리는 \n",
      "9 ----> 몇이야\n",
      "11 ---->  ?\n",
      "질문 데이터의 크기(shape) : (926, 40)\n",
      "답변 데이터의 크기(shape) : (926, 40)\n",
      "[2067 1560  376    6    9   11 2068    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[2067 1851   20 1852   13   12    7    1  417    2    8    1 1859    3\n",
      "   30    2    5    1 1859    3   57    2   10    1 1861    3  145 2068\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))\n",
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))\n",
    "\n",
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))\n",
    "\n",
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)\n",
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2067 1851   20 1852   13   12    7    1  417    2    8    1 1859    3\n",
      "   30    2    5    1 1859    3   57    2   10    1 1861    3  145 2068\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[2067 1851   20 1852   13   12    7    1  417    2    8    1 1859    3\n",
      "    30    2    5    1 1859    3   57    2   10    1 1861    3  145 2068\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[1851   20 1852   13   12    7    1  417    2    8    1 1859    3   30\n",
      "     2    5    1 1859    3   57    2   10    1 1861    3  145 2068    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
    "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2069, 256)\n",
      "(1, 2069, 256)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyper-parameters\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 5.3800 - accuracy: 2.2152e-04\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 5.2598 - accuracy: 7.7532e-04\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 5.0316 - accuracy: 0.0145\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 4.7511 - accuracy: 0.0869\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 4.4880 - accuracy: 0.1053\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 4.2736 - accuracy: 0.1054\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 4.0994 - accuracy: 0.1065\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 3.9431 - accuracy: 0.1078\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 3.7810 - accuracy: 0.1128\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 3.5933 - accuracy: 0.1289\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 3.3701 - accuracy: 0.1759\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 3.1118 - accuracy: 0.2421\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 2.8212 - accuracy: 0.3340\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 2.5159 - accuracy: 0.4223\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 2.2224 - accuracy: 0.4722\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.9647 - accuracy: 0.4997\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.7434 - accuracy: 0.5183\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.5629 - accuracy: 0.5279\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.4203 - accuracy: 0.5326\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.3092 - accuracy: 0.5346\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.2221 - accuracy: 0.5375\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.1523 - accuracy: 0.5394\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0917 - accuracy: 0.5421\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0406 - accuracy: 0.5433\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.9951 - accuracy: 0.5434\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.9559 - accuracy: 0.5449\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.9203 - accuracy: 0.5458\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.8902 - accuracy: 0.5465\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.8642 - accuracy: 0.5471\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.8402 - accuracy: 0.5481\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.8211 - accuracy: 0.5483\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.8021 - accuracy: 0.5493\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.7853 - accuracy: 0.5493\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.7684 - accuracy: 0.5509\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.7520 - accuracy: 0.5519\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.7351 - accuracy: 0.5541\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.7184 - accuracy: 0.5561\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.7031 - accuracy: 0.5579\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.6885 - accuracy: 0.5606\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.6717 - accuracy: 0.5622\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.6560 - accuracy: 0.5647\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.6417 - accuracy: 0.5671\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.6269 - accuracy: 0.5697\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.6132 - accuracy: 0.5722\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5984 - accuracy: 0.5745\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5833 - accuracy: 0.5773\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5689 - accuracy: 0.5795\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5533 - accuracy: 0.5834\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5373 - accuracy: 0.5866\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5232 - accuracy: 0.5905\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5083 - accuracy: 0.5939\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4948 - accuracy: 0.5962\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4810 - accuracy: 0.5999\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4663 - accuracy: 0.6038\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4515 - accuracy: 0.6053\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4382 - accuracy: 0.6088\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4214 - accuracy: 0.6148\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4074 - accuracy: 0.6174\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.3934 - accuracy: 0.6208\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.3804 - accuracy: 0.6224\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.3675 - accuracy: 0.6263\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.3509 - accuracy: 0.6303\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.3383 - accuracy: 0.6335\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.3215 - accuracy: 0.6378\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.3087 - accuracy: 0.6416\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2958 - accuracy: 0.6438\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2830 - accuracy: 0.6477\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2726 - accuracy: 0.6498\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2589 - accuracy: 0.6532\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2458 - accuracy: 0.6558\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2309 - accuracy: 0.6609\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2198 - accuracy: 0.6621\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2061 - accuracy: 0.6663\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1926 - accuracy: 0.6697\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1837 - accuracy: 0.6715\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1718 - accuracy: 0.6746\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1623 - accuracy: 0.6758\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1518 - accuracy: 0.6782\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1418 - accuracy: 0.6808\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1309 - accuracy: 0.6831\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1207 - accuracy: 0.6860\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1111 - accuracy: 0.6878\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1036 - accuracy: 0.6881\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0975 - accuracy: 0.6895\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0899 - accuracy: 0.6908\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0809 - accuracy: 0.6932\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0733 - accuracy: 0.6942\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0691 - accuracy: 0.6946\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0624 - accuracy: 0.6956\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0588 - accuracy: 0.6957\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0542 - accuracy: 0.6970\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0479 - accuracy: 0.6979\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0435 - accuracy: 0.6985\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0413 - accuracy: 0.6986\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0370 - accuracy: 0.6989\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0349 - accuracy: 0.6990\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0317 - accuracy: 0.6994\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0292 - accuracy: 0.7000\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0279 - accuracy: 0.6997\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0251 - accuracy: 0.7006\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('Not JSON Serializable:', <tf.Tensor: shape=(1, 2069, 256), dtype=float32, numpy=\narray([[[ 0.        ,  1.        ,  0.        , ...,  1.        ,\n          0.        ,  1.        ],\n        [ 0.841471  ,  0.5403023 ,  0.80196184, ...,  1.        ,\n          0.00010746,  1.        ],\n        [ 0.90929747, -0.4161468 ,  0.95814437, ...,  1.        ,\n          0.00021492,  1.        ],\n        ...,\n        [-0.91995513,  0.39202362, -0.09280269, ...,  0.97167504,\n          0.22019461,  0.97545594],\n        [-0.1671774 ,  0.9859268 ,  0.7431245 , ...,  0.97164774,\n          0.22029944,  0.9754323 ],\n        [ 0.7393025 ,  0.67337346,  0.9805654 , ...,  0.97162044,\n          0.22040424,  0.9754086 ]]], dtype=float32)>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5de44c7c0970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_name.5h\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1976\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \"\"\"\n\u001b[0;32m-> 1978\u001b[0;31m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[1;32m   1979\u001b[0m                     signatures, options)\n\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    131\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[1;32m    132\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0m\u001b[1;32m    134\u001b[0m                           signatures, options)\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# we use the default replica context here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m       \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    973\u001b[0m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m   _, exported_graph, object_saver, asset_info = _build_meta_graph(\n\u001b[0m\u001b[1;32m    976\u001b[0m       obj, export_dir, signatures, options, meta_graph_def)\n\u001b[1;32m    977\u001b[0m   \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_schema_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_SCHEMA_VERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, export_dir, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mfunction_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfdef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m   object_graph_proto = _serialize_object_graph(saveable_view,\n\u001b[0m\u001b[1;32m   1076\u001b[0m                                                asset_info.asset_index)\n\u001b[1;32m   1077\u001b[0m   \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_graph_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_serialize_object_graph\u001b[0;34m(saveable_view, asset_file_def_index)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_proto\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m     _write_object_proto(obj, obj_proto, asset_file_def_index,\n\u001b[0m\u001b[1;32m    721\u001b[0m                         saveable_view.function_name_map)\n\u001b[1;32m    722\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_write_object_proto\u001b[0;34m(obj, proto, asset_file_def_index, function_name_map)\u001b[0m\n\u001b[1;32m    759\u001b[0m           version=versions_pb2.VersionDef(\n\u001b[1;32m    760\u001b[0m               producer=1, min_consumer=1, bad_consumers=[]),\n\u001b[0;32m--> 761\u001b[0;31m           metadata=obj._tracking_metadata)\n\u001b[0m\u001b[1;32m    762\u001b[0m       \u001b[0;31m# pylint:enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregistered_type_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_tracking_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3009\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_tracking_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saved_model_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_list_extra_dependencies_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py\u001b[0m in \u001b[0;36mtracking_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# TODO(kathywu): check that serialized JSON can be loaded (e.g., if an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# object is in the python property)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_properties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlist_extra_dependencies_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/saving/saved_model/json_utils.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_encode_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/saving/saved_model/json_utils.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'TensorShape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'items'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mserialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_json_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/serialization.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not JSON Serializable:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ('Not JSON Serializable:', <tf.Tensor: shape=(1, 2069, 256), dtype=float32, numpy=\narray([[[ 0.        ,  1.        ,  0.        , ...,  1.        ,\n          0.        ,  1.        ],\n        [ 0.841471  ,  0.5403023 ,  0.80196184, ...,  1.        ,\n          0.00010746,  1.        ],\n        [ 0.90929747, -0.4161468 ,  0.95814437, ...,  1.        ,\n          0.00021492,  1.        ],\n        ...,\n        [-0.91995513,  0.39202362, -0.09280269, ...,  0.97167504,\n          0.22019461,  0.97545594],\n        [-0.1671774 ,  0.9859268 ,  0.7431245 , ...,  0.97164774,\n          0.22029944,  0.9754323 ],\n        [ 0.7393025 ,  0.67337346,  0.9805654 , ...,  0.97162044,\n          0.22040424,  0.9754086 ]]], dtype=float32)>)"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "EPOCHS =100\n",
    "model.fit(dataset, epochs=EPOCHS)\n",
    "\n",
    "from tensorflow.python.keras.models import load_model\n",
    "model.save(\"model_name.5h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/lib/python3.8/dist-packages\n",
      "sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/lib/python3.8/dist-packages\n",
      "sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/include/python3.8/UNKNOWN\n",
      "sysconfig: /usr/include/python3.8/UNKNOWN\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/bin\n",
      "sysconfig: /usr/bin\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local\n",
      "sysconfig: /usr\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.8/dist-packages (from keras) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.8/keras\n",
      "  sysconfig: /usr/include/python3.8/keras\u001b[0m\n",
      "Successfully installed keras-2.4.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install python-telegram-bot --upgrade\n",
    "!apt-get install telepot \n",
    "\n",
    "from telegram.ext import Updater, MessageHandler, Filters, CommandHandler\n",
    "import telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-alternatives: error\n",
    "from telegram.ext import Updater, MessageHandler, Filters, CommandHandler, CallbackQueryHandler # import modules\n",
    "from telegram import InlineKeyboardButton, InlineKeyboardMarkup\n",
    "my_token = '1926778534:AAHa9CdhfpVjh4qFveivJH_AN7w4KPUntAA'\n",
    "\n",
    "a=\"\"\n",
    "b=\"\"\n",
    "\n",
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "\n",
    "\n",
    "updater = Updater(my_token, use_context=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_message(update, context):\n",
    "    a=predict(update.message.text)\n",
    "\n",
    "    \n",
    "    update.message.reply_text(a)\n",
    "    output = predict(update.message.text)\n",
    "\n",
    "print(\"텔레그램 연결\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "--- a/src/transformers/modeling_tf_bert.py\n",
    "+++ b/src/transformers/modeling_tf_bert.py######\n",
    "def build_menu(buttons, n_cols, header_buttons=None, footer_buttons=None):\n",
    "    menu = [buttons[i:i + n_cols] for i in range(0, len(buttons), n_cols)]\n",
    "    if header_buttons:\n",
    "        menu.insert(0, header_buttons)\n",
    "    if footer_buttons:\n",
    "        menu.append(footer_buttons)\n",
    "    return menu\n",
    "\n",
    "def get_command(update, context):\n",
    "    print(\"get\")\n",
    "    show_list = []\n",
    "    show_list.append(InlineKeyboardButton(\"칼로리\", callback_data=\"칼로리\")) # add on buttonMultiHeadAttention, self\n",
    "    show_list.append(InlineKeyboardButton(\"운동\", callback_data=\"운동\")) # add off button\n",
    "    show_list.append(InlineKeyboardButton(\"신체정보수정\", callback_data=\"신체정보수정\")) # add off button\n",
    "    \n",
    "    show_li\n",
    "--- a/src/transformers/modeling_tf_bert.py\n",
    "+++ b/src/transformers/modeling_tf_bert.pyst.append(InlineKeyboardButton(\"cancel\", callback_data=\"cancel\")) # add cancel button\n",
    "    \n",
    "    show_markup = InlineKeyboardMarkup(build_menu(show_list, len(show_list) - 1)) # make markup\n",
    "\n",
    "    update.message.reply_text(\"메뉴를 선택하세요\", reply_markup=show_markup)\n",
    "#################\n",
    "\n",
    "def callback_get(update, context):\n",
    "    data_selected = update.callback_query.data\n",
    "    print(\"callback : \", data_selected)\n",
    "    if data_selected.find(\"cancel\") != -1 :\n",
    "        context.bot.edit_message_text(text=\"취소하였습니다.\",\n",
    "                                      chat_id=update.callback_query.message.chat_id,\n",
    "                                      message_id=update.callback_query.message.message_id)\n",
    "        return\n",
    "    \n",
    "    elif data_selected.find(\"칼로리\") != -1 :\n",
    "        context.bot.edit_message_text(text=\"칼로리 메뉴가 선택되었습니다.\",\n",
    "                                          chat_id=update.callback_query.message.chat_id,\n",
    "                                          message_id=update.callback_query.message.message_id)\n",
    "        return\n",
    "    elif data_selected.find(\"운동\") != -1 :\n",
    "        context.bot.edit_message_text(text=\"운동 메뉴가 선택되었습니다.\",\n",
    "                                          chat_id=update.callback_query.message.chat_id,\n",
    "                                          message_id=update.callback_query.message.message_id)\n",
    "        return\n",
    "    elif data_selected.find(\"신체정보수정\") != -1 :\n",
    "        context.bot.edit_message_text(text=\"신체정보수정 메뉴가 선택되었습니다.\",\n",
    "                                          chat_id=update.callback_query.message.chat_id,\n",
    "                                          message_id=update.callback_query.message.message_id)\n",
    "        return\n",
    "#     context.bot.edit_message_text(text=\"{}이(가) 선택되었습니다\".format(update.callback_query.data),\n",
    "#                                   chat_id=update.callback_query.message.chat_id,\n",
    "#                                   message_id=update.callback_query.message.message_id)\n",
    "\n",
    "#     update.message.reply_text(\"ㄴㅇㄹㅇㄴㄹ\")#format(update.callback_query.data)+\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "message_handler1 = CommandHandler('menu', get_command)\n",
    "\n",
    "\n",
    "message_handler2 = MessageHandler(Filters.text, get_message)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "updater.dispatcher.add_handler(message_handler1)\n",
    "updater.dispatcher.add_handler(message_handler2)\n",
    "\n",
    "####################\n",
    "\n",
    "updater.dispatcher.add_handler(CallbackQueryHandler(callback_get))\n",
    "\n",
    "####################\n",
    "\n",
    "\n",
    "updater.start_polling(timeout=3, drop_pending_updates=True)\n",
    "updater.idle()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
