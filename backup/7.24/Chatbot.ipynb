{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    angle_rads = np.zeros(angle_rads.shape)\n",
    "    angle_rads[:, 0::2] = sines\n",
    "    angle_rads[:, 1::2] = cosines\n",
    "    pos_encoding = tf.constant(angle_rads)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "    print(pos_encoding.shape)\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABSp0lEQVR4nO2dd5gV1fnHP+/2ZYFdeq+CCIiCorFFEXuKmPxM1MTEWGMSa+wx1mgsiRqNFXuMnViwiwpiF1QQFBCk9963sLvn98d7Zu69s3fZu7B938/zzLP3nJk5c+7s7rlzv28T5xyGYRhG8yCtvidgGIZh1B226BuGYTQjbNE3DMNoRtiibxiG0YywRd8wDKMZYYu+YRhGM6JWF30RmS8i00RkiohM9n1tRWSciMz2P9vU5hwMwzDqCxF5RERWisj0SvaLiNwlInNE5GsR2Stu3yl+nZwtIqfU1Jzq4kn/UOfcUOfccN++HHjXOdcfeNe3DcMwmiKPAUdvZ/8xQH+/nQXcB/pwDFwD/ADYF7imph6Q60PeGQU87l8/DhxXD3MwDMOodZxzE4G12zlkFPAfp3wKFIhIF+AoYJxzbq1zbh0wju1/eKRMRk0Msh0c8LaIOOAB59xooJNzbpnfvxzolOxEETkL/eQjE9m75+Ah4b4N38wEoMewwdqeNgOA1V17AZDfIhOApUvWAJDTqhUAXdcuBmBjcSkArQbtBsD384LpwLDeBQCs/24RAGu69tZz83O0Pe1bHaNjDwDSM9IB6LxyIQCr/Bx6bFkOQNGG4nDs5Z166lhrdB7fZ+i8+vTSW5AhAsB3fj6DcksAmE1bAApW63nt9xikc5g+Ixy7XTedd3lpmd6TlZv02CH6HhdO0WNb7DYAgNJZ3+n77Kxz6r5+CQBzs/Vag1uWhGN/vVajtvfqo/u+nLsagKG76blTZum8BuzSVec7f6W+z27t9H2v2AhAq4K8cMwtW3T8jEy9f65cr1Huf2ZmaX9x4TYAWrbKBmDT+i0AtG3XEoA1q3Xszp0KwrGXLdP/sR7++gsXrwKgd4+OAMxfuAKAXXp3BmCOv9+79u0CwHffLwVgt37dAJg5Z3E49qB+3QH41vcN7q9/B9/MXpS0vbtvT/9O/z6GDNB7Nm1WYju+bw/f93VlbX/fv56ZvL2nb0/17WR90Xb4u0yxnfyYXr69YKfaCX0D/TEzUmsDuMI1q51zHdhB0lp3d5QWpXSsK1zzDRB/8Gi/zqVKN2BRXHux76usf6eR2kzDICLdnHNLRKQj+kl1LjDWOVcQd8w659x2v7Z0Tst2o6fHfqmvD94PgH9u0YXszT6qHD1y3YMA/GhP/ee96prHANhtxMEAXP/EpQC88/06AH449RMAfvG768OxN40eBcBLR14IwON/ewiAa48ZqO3ewwAYd96dABR00IXs0rvOA+DBa3UOt312MwCz35wbjn3L+XfpWI9fAsDPOxwKwJP3XwxAmxz9sDrq19cB8NUQXViOKj8BgGMfVSXs94unAvDWroFiBqfcpPMuXLVe79FdH2j/go8BOD9fpcJhn74PwIoRhwHwyuX3AnDrS1cBcEJvvdb0A2P3u9fz+iG5+fETAcg96VEA1n50DwAdDtX5j3/ubwAcc6bem79d9zsAbrprHAAjfxzKlUyapB8y7bu2BqC4SBf3oi36s2N37Z//rX6AHHCQ/nO/99qXAPz6VwcC8NgjbwFw+Z9HhWPfcOOTANxx46kAnHfJfQA8cuc5APzuT7cD8OLDlwFw7G913u88fQ0Ah51wNQCfvHAjAPsdF1Mgv3zlVgD2+qn+LU177R8A7H7MnwGY8ZaOPfAobc8edwcA/Q7Tv4957/0bgD4jzwVgwfh/h2P3OlT7Fk/Qvu4jtL3k/bsB6HaIzn/ZRG13OVjby327s2+v/EDbHX94Tjj2qg/97+qgPyVtr/G/y3YHJm8Hv+u2vp2sb/3H+rdUcMAfd6od37fhE+3L3z+1NsC2KY9+EScnV5u0Fu1dxoBjUzo2lWuJSG/gVefc7kn2vQrc7Jz70LffBS4DRgA5zrkbfP9VQKFz7p/VeCtJqVV5xzm3xP9cCbyIalMr/NcX/M+VtTkHwzCMaiGCpKWntNUAS4Aece3uvq+y/p2m1hZ9EckTkVbBa+BIYDowFggs0acAL9fWHAzDMKqPkJaRldJWA4wFfuu9ePYDNnj5+y3gSBFp4w24R/q+naY2Nf1OwIuiOnUG8JRz7k0RmQQ8JyKnAwuAX9biHAzDMKqHf9KvmaHkaVSqaS8ii1GPnEwA59z9wOvAj4A5wFbgVL9vrYj8DZjkh7reObc9g3DK1Nqi75ybC+yZpH8NcFh1xmqdmU7Pq2JuqmccswsAn+6jWv34VWrcG/tTbxpYOQuASzaowfHr118F4JCHVMN95WD9+aNstZO48rJw7O86qb3gozVbAbj08F0BeOgz1biHtVaD4uphajeY+NbXAEzzBttRw9TW0i17KAAvPxcztq5ctAGAjkPUoJhd2B6ALxatB+C04WokLC3aDMD6eWp7aLmn2g1KvJGzba7+QbbNiv1hblmi77VVTzUKby4t13Mycoln3VY1oOam65e8kkLV67P9+yorLgQgMy92nivX+UlW4lglZTqf4B+k2F8zaBeW6H0NnohK/H49Ro3WZWXal+aN2IFBN9gfGHbT0xK/lKanBceXJbTj+6IE16iM6P7tHV/ZNbZ/hSTHV/eEGiKtiuvW07QaBAJIes0s+s65k6rY74A/VbLvEeCRGplIHLXtvWMYhtG4ECGthp70GyK26BuGYUSoKXmnIWKLvmEYRjw1qOk3RGzRNwzDiEMQ0jIy63satUajWPRzBu7G/S/MCtuXrpoGwKMdNUr3zJ9plOk7B/8KAOeNg/ueq0FCk8a8AMDEjhoMdUwPDfz55koNwuk4OGZr+curGnHb2Rsp92uxHoCzP9aow9P3V0Nt5+HqQvvy6KcAWOGjfE/yUat5rUb6/ifCsTcsnafn7t9Pj5mpEY1fLlCD7V8OSgy427hYo03zD2uR0N/Ge4olGHKXa/Rx++EapRwYcjeXlCecu3KjGpz7pquprsTPOytP/8jLS9XQm9k6dk1XrmOXRw25gdHVG72K/DXTMnWCgSE32F8cZ8hN94bkwHCblpHYrsxQG7SzwuMrGnIDYsbhxGPKfbsqY2YyoufUhyG2ORtZ6wR70jcMw2he2KJvGIbRXBCpMZfNhogt+oZhGHEI9qRf73w7bwUTH4gFZw0+92kAPrrkEABa/VUTat3felDCea/+4QcAHOEDkC544DMAPrvpFwD863TN8HzEI7E8SG+8+CkAl/msjuuf1uRVS6erHWDgqWoXGNA7H4BtWzTgypsA6C2qz5f22huAwrJYQrvCNZq9MX/oUADarC/QsX3QVsba+UDsD27tGg2U6tA+UdNP36gZPFu0jWnsm5ZpQFd6Ow0aK/LaeKDpewmftT675R5eE9/mNf3sfH2/5Ss04Vl6XkE4dqCJu8zEeQTBWYFP89ZtZQnzjwZnBW09JjE4KysjI9JO1Oyr0vDTk4jr6ZGuaLBV9Jxouyb0+prIc1KV7WFHbBPGdpA00msmxUKDpFEs+oZhGHWG2JO+YRhGs0Ew7x3DMIxmhS369UxaegYXtDw+bK9fpL7vX191CwBX3TgBgPsOVr/3FbPUr3zpBb8G4LG/PQbAnj+6CIAtV/0LgEWFWiDlr4f3C8f+7z+0KMOBB2nys6kPfajnZGlMQNbh1wIgs7VISbr3XQ985sunvgvAnMH/p8fHCa4lXv/PGKRJ3drN1KR5c6drJaeyxVrNKiNXq0ItL1L9emAXtSds8WMFmn5ep5jGvmWFJp3LaK/VoAq9Nr6xuCxhHgs3q59+y0DTL9KiP1mttDJY+RLV/KVFa6K4TNX9g3+ICgnXyhITrkUTsJXG++lneJ/5wLe/RWLCtQp++pX43LuywOe+YsK1tAq6f4W3lEBVCdmgap0/GhtQcX+Vl0B20piws+c3e8xP3zAMozlhi75hGEazQUTCqPKmiC36hmEY8Zi8YxiG0bywRb+e2b13O576x91h+/Z7rwLglAs0KGvLKq2AtddHbwCQ9sUrAFx12F8AuOaI+wHIbaNVpS56RatZHeaDm7rNeC0cOzCiDj57FAC3nHAXAOl76LFTClvpOa+8CEB+990A2HXOewAsGzcBgA99wrX2cUnRAuNeYdu+AOzdR/unjdeKaCVzNcAqyxtR1/lgp/6ddE5zAuPr4u8BaNkpLxx77WwNCqOVVuMKkqGt9pWyAkPuJh+clevnFVTKymqrY4XJyFoVECUIzqrUkOuNskFgS6Gff7qfdxB4BTFjY1AZKy1SKSs7CMYqqyQYKwUjbdVG1eT7Q0NwCqnNLDCqaRJ1AmhK1FphdMMwjMaIiCBpqW0pjne0iMwSkTkicnmS/XeIyBS/fSci6+P2lcXtG1sT769RPOkbhmHUJUHq751FRNKBe4AjgMXAJBEZ65z7NjjGOXdh3PHnAsPihih0zg2tkcl47EnfMAwjHqEmn/T3BeY45+Y650qAZ4BR2zn+JODpGngXldIonvTXT5vBTx+4L2yf9IUGUF2b3Q6AXQ/7OQCH/PNjAM75yUFATMd+/RxNrHbAdQ8CMO7FjwC45cIRAHx904Ph2D33OV9fHHkkAMuLbgegTW9NyvbgpwsAOPmVqQB0O1J/f/1XqJa+cMJsAN4eoAFU/9cy5voVJB77fp0GSO3VswCA+9dpcNa6GasByG0zHIgVQtmljWrpy/zTx7Zl8wHI61wQjr2hSPvK8vSeBHne1kQ0/WKffC67tQZalZWopp9doHaD8m16fFqLVkQpz8xJaJeEwVg6r8oSrgVPTWUJwVlBwjevnwdFVVzy4KxA4y+vpKhKvAbryhOTzAWEGn5oJ0jcX0MPd9XCnrpiNJSYMs2yWWOT6QYsimsvBn6Q9LoivYA+wHtx3TkiMhkoBW52zr20sxNqFIu+YRhG3SEpRWd72vtFOWC0c270Dl74RGCMcy7es6CXc26JiPQF3hORac6573dwfMAWfcMwjESkWk/6q51zw7ezfwnQI67d3fcl40TgT/Edzrkl/udcEZmA6v07tejbt0vDMIwINajpTwL6i0gfEclCF/YKXjgishvQBvgkrq+NiGT71+2BA4Fvo+dWl0bxpF9c5ng8+62wfdVZYwAYO0e/VfVto1pzzxHnAnDFrAMB+OCcAwC45TZNjvbEr4cC0OUBTbTW7jHV6/9z0z7h2KddpoVYnp6+EoDOOXqL+gzT4usffKIF0ofN0mRpB12uxcx7pam//ut36bW+n6NJ33oNaBeOnZOjuv9nizXx2kE92wCxRGxrv9MiK3kdEpOm9fAFToKkbpsWqg2gZbcO4dhrvX5e3qIN8azymn6O191LCrVISlZLLYRe6jX9LF8I3ZVr4ra0vIoJ16J++YGGnxbxyw/aJaWBxu998OMKygQ6f3G52hgCTT7Q/asqjJ5KEZUKRVMi50T3R9vJvuFHffejh0TPacrJz6ohgTQqRGIJAXcW51ypiJwDvAWkA484574RkeuByc654APgROAZFxi1lIHAAyJSjj6g3xzv9bOjNIpF3zAMoy6pyQ9r59zrwOuRvqsj7WuTnPcxMKTGJuKxRd8wDCMOEWnSEbm26BuGYUSoQZfNBoct+oZhGBFs0a9nuuy+C5f95pGwfXhHTQ7W7u9nArBqk1Z/6rn/GQAs/ORVAHLv1URrez60NwAld18CQOvuuwJwy6dqEF26dVs49u37asWskbdpxay/928LQKcRmiTtL1c/CsB3vgLVSXupIbdj+8MA+P4mrZy1at5iALod2DccO2+hVvb6cPYqAH41pCMA5aVqbF07W43DBYP1/QV2z44t9NfUIVsNqJu9IbfrwUPDsTdsUwPoptLEP9bl6/XedPbBTUFwVo43fgcJ17ILNBjLlW/Un5m5RIlWwtq6LbEdBGMFuci3bic4KzTu+r6MIMGaN9RmZaQntCtLuBYGZyWpnFXRcFvhLaVEZQnbdoQdkYprYvmp6r033SVuB5Cma6SGRrLoG4Zh1BWCkJbRdL3ZbdE3DMOIR5p2amVb9A3DMCI05fiKRrHof7OihHuPjGnjQ//7HwDO66CJ1YLEWm8sPwKA427WwKPj/q3BbS//Rfufv/FtAPa+Se0Djzw7BYAzczPDsctfuBWAOZ+pLr3nWYcAMGigBkKd7wu2FHrBfVgQC5WvRVMCbX3zivkAdDpp73DsNmVdAfhurhY8yd2wOOF9rlmqRVQ6+KIpAdlb1AaQ31Z1+I0+uKtnh27hMVt8INcGn8AsuCcrN6ntoV9GkHBN7RdhwrXVqvmn56ntItCvy7MT5wBQFARnpUeCs7yGH2j6YZEVr9enJSmikpWtf3rlPhYlK6LpVxWclRXJjra9IiphkrZosFYVwVjJHvaqWgtqQhSo6iGzCT+ENgg04Vp9z6L2qPW3JiLpIvKViLzq231E5DNfUOBZH5psGIbRMPDyTipbY6QuPs/OB2bEtW8B7nDO9QPWAafXwRwMwzBSREhLT0tpa4zU6qxFpDvwY+Ah3xZgJDDGH/I4cFxtzsEwDKM6SBN/0q9tTf9fwKVAUJGjHbDeOVfq24vRIgMVEJGzgLMAJKsVG//9cbjvB3doorW79tNTl36vGrlcr18anrlSi6Lsc+xlAGS8p4nVpl+mBdPv+cUeAAx++DEADj+wezj257eoj//GdC2a0voXWoQ9bdGnAKRnqf96kPyMyXr8nEHH6X7/d1C0QXX4rGEnhWN3mr8egPnfajK38vlf6/xyVD9f4n3od++Wr2P4P6r0dWpHyPPxCZuWqfaf0blnOHaQnG1Dkde8/bkLN6pmn5/pdfZC9cvPKdD3Ub7cF01plZiozWXF/PSjhdCDwufRoimBX36QcK048NPPSPTJB0hrkdhXmWYf89tPLJQeLWqe7B8wmc4fT1W+2KnY8qouvr7982vCYNiUjY71RVMOzqq1J30R+Qmw0jn3xY6c75wb7Zwb7pwbTpJAIcMwjNpARB9CUtkaI7X5pH8gcKyI/AjIAVoDdwIFIpLhn/a3V1DAMAyjXmisC3oq1NqTvnPuCudcd+dcbzRX9HvOuV8D44Hj/WGnAC/X1hwMwzCqi5DaU35j/WCoDz/9y4BnROQG4Cvg4XqYg2EYRlJEYjakpkidLPrOuQnABP96LrBvdc7fpXdnRp3697C9zVea6j9Bg60OWDIJgIv3OBWAqwffBEDLzr0B+M2TUwA4zRtCu0/6LwDZrTQgaegVp4ZjX3fMdQBk7KXG1Y83qw267zNPAdCmt5bD3H3ueAAWv6y1EcZla6BY1xwN9AoMexsKdgnH3r//AgC+fleNwkUzNwGQk68VtVaXqCF3iDfkzvB/eNsWfgdA6+46l/njtXoX+R3DsUvK1ci6cosGYwWG3E1b1FCb6w3PpYVqBM7uqWOVbQsMuQXE4zJbhK8DQ21xafLKWemRylnpkWAsCYOkYkWBAsNr0JcdMdRWlmAtbFcIpKqYcK2yylhRo2t4fAppx3b24a7pLiXVp6Han0Ugo5E+xadCo4jINQzDqCuEpq3p26JvGIYRjzRevT4V7NumYRhGHPqkn5bSltJ4IkeLyCyfeubyJPt/JyKrRGSK386I23eKiMz22yk18f4axZN+5uJ59DhsRNju65Of7XeRBkYdc/RuAAxrpUnEHr30BQD+NEYLzd/5D9Xwx9yt9+zjy7UQysDjbwRg1dD9w7HXlmi94o6DDwTglnGqp5//3Fd67dNPBmDAVg0Mm/OG7h+7i3qeXligSdGCgKtpK7eGY+/XW20Id6xZCsDqr7UYSl6HIwHY7AOVdmuvtoflPqCqaMH3ALTuqRr+6uK5AJS16hSOHRRcWRlo+D64qXCTbwdFU0qCoik6vzChWUTTL8vICV8HGn5RmEBN7RbFYTsx4Vq0aEqg8W8rjmnpQQh7eVny4KxA4y+vJOFaWtj252/nwSxmJ0jsj7YrJFxLQeOPntNUA6WaclGRZNTUk76IpAP3AEegwaiTRGSsc+7byKHPOufOiZzbFrgGGA444At/7rqdmZM96RuGYcSRJkJWRlpKWwrsC8xxzs11zpUAzwCjUpzKUcA459xav9CPA47eoTcVhy36hmEYEdJFUtqA9iIyOW47KzJUN2BRXLuy1DP/JyJfi8gYEelRzXOrRaOQdwzDMOqKIA1Diqx2zg3fyUu+AjztnCsWkd+jiShH7uSYldIoFv3VG4pZetlusY5V6u/e6tGJAPxnpvq93/nq9QBcfLAmWvtXf/VJv3mdaufzf3gpAK/P0ILp/zx5LwBufO/7cOi9vCa/7qA+AHw0bhoAny3SguG/8QXS+3dUO8C4c54GYOGs1QD0OEiTt7Uo1IIp789dE459ii+iHsQZrJq+DID8PdVPPyjM0r21auRBIfQNc9Re0KqnavhrvXZenBXksYuxzCdYy/OCdZEv+h4UQt/m/fRzwkLo6wGQFvkJ4xQlFDH3Bdl9HEHYLtZ2TNMP2nrtUl9QJtD4i0pjBejTQ80+KKKSvBB6hYRrlRRESaY5VyyMXvU58ddIRnWV3vqQwlNZr5qXQl99atB7ZwnQI65dIfWMc25NXPMh4Na4c0dEzp2wsxMyeccwDCOOIDgrlS0FJgH9ffGoLDQlzdjE60mXuOaxxOqPvAUcKSJtRKQNcKTv2ykaxZO+YRhGXSFIjaVhcM6Visg56GKdDjzinPtGRK4HJjvnxgLnicixQCmwFvidP3etiPwN/eAAuN45t3Zn52SLvmEYRhzV1PSrxDn3OvB6pO/quNdXAFdUcu4jwCM1Nhls0TcMw0jA0jA0ALr1assdu/40bAeBOJf64Kt77n4JgJu37gnAr0f2BmDCcX8EoP+R+qF66ujPADjAqfHwgK1TADj59RXh2Bf8YhAAex+2KwAH3qMfskuL1Eh59m5qdM3r/H8ALCr8DwBr52msRa/jhgFQMEXPf2/68nDsy/dJrE61drZ+U2t3dMuE/rZpmjStQwsNgtowX+fX4UB1EtjojazriioaHBev1eCrwf7raXGhGk/D4KzNPjirrRpuXbnakMqz8xLGKSyNJUeT9MQEa2mZarjd7O9J0N4aCc4qD4O3EhOwQUXDbFXt6D9hZsTQG7+/PEy4lnBKBeNvlOjxdWGETba2RLua8PrTMKnhJ/2GRqNY9A3DMOqKIJ9+U8UWfcMwjAi26BuGYTQT0qyISv2zKK0NHbJjGvOSQtWSL107BoC+12oitfMuuQ+AK559HIBzOx4MwL/+9wMAjv3t3wC4ob8mPvvqUi3MsmJV/3Ds/k9rAJfz0c+BZpzrDQlt53+kc+hxABBLdLZllR7fesRvAOi8ThOdLZ+/Phw7bcEUANKztND7og2q3Q/xidiCJGIZa+brWL5oyvr5GsyV2aU3EEvMtj5O0w+KpizZoJr9AZmJmn4QnFW+Xttp+e38+5ut/dl6rbBgSpz+nub7NnnNPppgrULCtYiGn5mtf2blpRU1/fJSvU9Z6ck1/CBZWmZa4v60KgKvoGoNf0c0+2ghlujSUNUDYlNNyNakME3fMAyj+SBIlQ8MjRlb9A3DMCI05VTStugbhmHEIWy/PkNjp1Es+muXr+TE1QvCtnz+EgBXH3kVANc8qZry+V73Pe2tlQAc1la184NXahHzwN/8oFvUBnDLCXdp/x6xZG5fZA0AoNvjfwGgTe/dAdhz/ocALH1GE6y9cZwe1zUn0KtVm97SXZO4HTBIC5089ulX4dhF032yM18IPfD936tXAQBzgkRl86YDUNBbfekXfrhY59lek7kVeq182abicOzA5rBmgyZcy/fzCpK75XTRscpm+0LoXtMPcNkaKxArmBJXxLxC4XNtb/IJ19LDBGte5/ZziRVRqVgYvbJC6FE//YDKCqHHErBRgQr6ewU9PvGkCkVUGug/vtkFahmpaDNqSjSKRd8wDKOuEGKOA00RW/QNwzDiMHnHMAyjOSFi8o5hGEZzQTDvnXqnoFMH+v/++bA94ig1rh7WKhuAu373IABXvv4GADdcp0nSRj/6BwDeP+MWAPb4jRakWXmgBmstL7odgM57HhqOfcXYbwC4+FGtxtX/7F8CMJSeAHz73BQAnumkhuWL27cAICNHDaGTlqqx9tD+aqy9Z1WsxOWKz7VSVstOWts4qID1006tAViTqUbUwjkzAcjvrZWyVr09D4CyfK21EASELdlUFI6d64ObCjepoTZIsFZa5I3H7fQa5dt0f3qrAuIpy9DjA0PulpJY4FdahiZ+21QSrZSVmGAtZrjV9rbiwLDrA7G2k3AtO6yklTzhWlpo6PXXqMSwC/HG4cRjou0KhtsU6klFz6nKqNpYleHaWPQa0zpq8o5hGEYzQQQyo08ITQhb9A3DMOIweccwDKOZYfJOPdNbNjJvxbyw/dwdmvTs0amacO3qXY4F4JqyjwG4tkSTjk3Y9QQAXp2l2v1/ztgXgHP+Nw2AUzpq4ZDsYwaEYz/73/cAmLh4IwAXHK37du17BABjX78fgHnTVZ/f5ai+ALRc01uv9Y0WPLl0RB8gFhwFsPyLJQC0O7gjACU+WKl3gWrknXNUT1/3ndoB2g7sBcAqr41vzUgstrJ4XWH4urXXwLdu9pp+ew1M21aomn6LjlrApbzUF4xpmRicVej1eAmTq5WG+wINPyyaEgRnFfnkbWFwlo6R4W0TRVt0f3qo18eCs9LTIgnXKimaErSjftPRJ7HMJP+l0WMqe3oLrhFlR/7v6+MBMRVHkya8htU4gtTok76IHA3cidbIfcg5d3Nk/5+BM9AauauA05xzC/y+MmCaP3Shc+7YnZ1Po1j0DcMw6owazLIpIunAPcARwGJgkoiMdc59G3fYV8Bw59xWEfkDcCtwgt9X6JwbWiOT8TRda4VhGMYOoJp+alsK7AvMcc7Ndc6VAM8Ao+IPcM6Nd85t9c1Pge41+HYqYIu+YRhGHEEahlQ2oL2ITI7bzooM1w1YFNde7Psq43Tgjbh2jh/3UxE5rgbeXuOQdxbPW83nn14cto+7eQIAP/yPFh1/4Vr1e3/k51oU5aC/PwzAH/6px52Zo37mXd+9E4BPXtG3/eiVet5BI/uGY993/R1AzIf+J728/3qP3wKwtOhuANbNnQpArwtGAtBxoo7x0VTV+tvvm13hfayco4XQu55ckNDfumg1AJ07qM//2ln6vroerWOv84nMVhcmJhdbsGZrOEZQNKVoi2rkLXz8QJkvlJ5ZoNd05UsBKM9plTCHLV6PD5LSbY7306+kEHrgpx9o+EHCtSxfNCUoopKbpfsD/R6q1vCz0pMnXAs1/vREv/5k+c+jfVUlVEtFxt3Zp6QK10zhGKOOkYoxHdthtXNueI1cVuRkYDhwSFx3L+fcEhHpC7wnItOcc9/vzHVq7UlfRHJE5HMRmSoi34jIdb6/j4h8JiJzRORZEcmqrTkYhmFUl8BlM5UtBZYAPeLa3X1f4jVFDgeuBI51zoXpc51zS/zPucAEYNgOvzFPbco7xcBI59yewFDgaBHZD7gFuMM51w9Yh36dMQzDaCBo5axUthSYBPT3D7tZwInA2ISriQwDHkAX/JVx/W1EJNu/bg8cCMQbgHeIWlv0nbLZNzP95oCRwBjf/zhwXG3NwTAMo7rU5JO+c64UOAd4C5gBPOec+0ZErheRwP3yH0BL4HkRmSIiwYfCQGCyiEwFxgM3R7x+doha1fS9u9IXQD/Ubel7YL2/EbAdo4Y3iJwF0JL02pymYRhGiKZhqDnDinPudeD1SN/Vca8Pr+S8j4EhNTYRT60u+s65MmCoiBQALwK7bf+MhHNHA6MBBuW3dgsOHRnu+/JzDaBqddD5AMx78R8AfHeV3texp+yh+x9Ug+4Jp6kM9ur5TwGwsdt+ALQ4814A0t7/Tzh2Tn4HAHrkqvG39DU9ZvK+ZwPQ0hsgC9epsTVjf+0fsFoNuJ+Pn6HnTVsIQHartuHYc2ZrsNKBPhnbav+HJYv1w7tNnwIA1s1dD0Bmz10B2OwDp1Z6I22Wt/TNWRsz5Lb1xtLiLfrlKq+jGmrLlmtStvQ2Hf2Rei3nDblBMFZhmCzNG22LY8FZYaUsb8jNyFIjdXGQcC2ojOXHSGuR2I4abSFmqI1WygqSpVWochWxbm4v4VplfVVVyqrs/MqCt/SY7Y9RE1WurFJW3dOUb3mdeO8459aLyHhgf6BARDL8035So4ZhGEZ9kkrG1cZKbXrvdPBP+IhILhqRNgPVpo73h50CvFxbczAMw6gugj7pp7I1RmrzSb8L8LjX9dNQA8arIvIt8IyI3ICGHz9ci3MwDMOoNk05VqLWFn3n3Nck8Sn1/qb7Vmes0p59eXPmmrC9bfBBAOx/rgZb/fLKlwD44ALt/+4MTVvRc/8zAOhxk9oD/nnPUAAKDtQiLH99ew4Ax9/+33DsPvtfDsAPCz8AYMo9bwHwwLajADgmX/XsIOnYd6UFABw3VL80vfNf/eKy+qNVALTstGc49gqvk/+olyY/+yRLb3/Jd18B0Ka/2hO+m6T2gbI26t4bJGZbuEH1+cCusHF9rIhKS180JUjwlttHr1FarMFZMU1fKc+OaPo+OCtWMCW+iEqizh8URSnx7SA4KyiaErSD4KywQMq2isFZlRVNCQxpQdGUzEjwVqi3JymYEgv4SmxXRU38o1uIe4zG+iRMI36KT4WU/kZF5OciMltENojIRhHZJCIba3tyhmEYdY3UrJ9+gyPVJ/1bgZ8652bU5mQMwzAaAibvwApb8A3DaC404TU/5UV/sog8C7yEplcAwDn3Qm1MyjAMo76wcolKa2ArcGRcnwPqZNH/ft4y/v7enWH74hFXADD+Z1pJKvepTwEovO0eAB7vMRSAh2ceDMAFby0AYK8CNXauG6UG3+fHTAag4POl4dh/vHUwAEMHaJDcvec8DcCkzxYDcNnI3gC0LNSf//MVtE7ZSwOLg6CtJR9rpa92e8ZSZwdBVgN9BsyFuXr7V0/5DoC2u+mYy4u+BKAor0PCfZjvg7FaZ6ihdOvG8POXPF8FrMQbcoNKWa58PQBp+e0TxtpaqsbhwEi7IVIVa6OvigWQnqVVuDb7voysIKumD+jyFtOi0sRKWWVhcFa6n0vMoJqdUUlwViVZM6P/hNEiF6kEZwXN0BgcDdaKnJ/s/z4aKNUQK2XtyJSa8iK3IzTl25HSou+cO7W2J2IYhtFQaMpeWKl673QXkRdFZKXf/icitVrdxTAMoz4QXy4xla0xkuoH2qNoOtCufnvF9xmGYTQ5LCIXOjjn4hf5x0TkglqYT1Iy81ox8uNOYfvZq9W08NDeJwNw0HUPAvDjq98G4FSvD+8zWfuPf0rf5vVXH6PHjVLdvs+d9wOwtCiWXOyyQfkAyK5/BGD+aZqMbeWMSQDsep5eu9PEfgC8/plWQvvL7omfn0unaVrsbj9rU+H9tN+mgWZd2qlWvmq62gs6HaY2iNU+MGrVVp1XkFxs7qotAPwgS6+1dVOcpt9JNf2gUlZ2R9Xwy0t1HuW5+Qlz2BqplLXBB1qlZ+ucNmyNafpBpaww4VoVlbLCwCtfKSvaju+rrFJWNBgrWikrs0ICtor/gTVRKWtnqapSViN9WGzSCCbvAKwRkZNFJN1vJwNrqjzLMAyjESIiKW2NkVQX/dOAXwLLgWVowjQz7hqG0fQQ/QaWytYYSdV7ZwFwbJUHGoZhNHKEivUamhLbXfRF5FLn3K0i8m/ULz8B59x5tTazOAZ3zmHSc0+F7Q8euRaARTepBv7mCepIlPeomh1Ov/wwAP579uMAbOh9AABlp/0bgDZvqz9/i3ZdAdglL1abfet/bwbgoxEXApCfmVg0Jf3QPwOw1+b5ALz3mvrUb/tiFhArwjLrO9WvjxrSORx7qdexmT8FgPYD2gGwepYqZZl91NYQ+PMv2qCafa7Xs2et1AIpP/EaetHGDeHYLbuoZr9tqer+6e0G+j1aNKW8hdoWggRrm7clFk0J/PSD9vo4TT8omlIYavo6n1Jve2jRMiuhnev9+IMEa7mZFf30qyqakhHR+CsrmhJNwJbQV0XRlOiTWoUxqYgVTWkeNOXfQVXyTpB6YTJa9jC6GYZhNCk0Irfm5B0ROVpEZonIHBG5PMn+bBF51u//TER6x+27wvfPEpGjauL9bfdJ3zn3in+51Tn3fGSiv6iJCRiGYTQ0auo539cTuQctIrUYmCQiYyMFzk8H1jnn+onIicAtwAkiMgg4ERiMusq/IyK7+jK0O0yqhtwrUuwzDMNo5AhpktqWAvsCc5xzc51zJcAzwKjIMaOAx/3rMcBhovrSKOAZ51yxc24eMIdq1iJJRlWa/jHAj4BuInJX3K7WQGnyswzDMBox1Qu8ai8ik+Pao51zo+Pa3YBFce3FwA8iY4THOOdKRWQD0M73fxo5t1vKM6uEqrx3lqJ6/rEkavibgAt39uKpsmL6HK5758Ww/fsL1RC7/LnzAZgwQkvu7v2bWwEo/b3e0y+v1QpZ3fb5EQAnP6EVqi6+Q5OoDTn7dgAOb/l5OPZn/9RKWbcV6zkXtdegp3/naHK3D1epPftXw7Wq1Qv3PwnA0nGaeC2/x9Ha/kA/E0/p3S4c+z1vgN3ylf4eO+yuBuhpH2twVmm73kCsUtb36zTBWlApa5MPvGrZQRO2bdsaM+S2GKTXCYynGe1jBmSA0iydf5BQbZOvcpWepUnoNhT7ZGlBcrXi2Gd6NBgrSKgWVMoKKmmV++CsFlmJhtvsSJUsiBl7K6uUFRhuU6mUlawNSQy3VXxpjx6fijGvsQbx1EaCtaZi+xTnkBSrrQGrnXPDa3M+NU1Vmv5UYKqIPOmcsyd7wzCaBeLKa2qoJUCPuHZ335fsmMUikgHko8GvqZxbbbb7oCIiz/mXX4nI13HbNBH5emcvbhiG0fBw4MpT26pmEtBfRPqISBZqmB0bOWYscIp/fTzwnnPO+f4TvXdPH6A/8Dk7SVXyzvn+50929kKGYRiNBlchLGkHh3GlInIO8BaQDjzinPtGRK4HJjvnxgIPA0+IyBxgLfrBgD/uOTTYphT408567kDV8s4y/3I1UOicKxeRXYHdgDd29uKpkinCiW/eELZvz98TgCvdSAC2zlRtfsJ5Kq0dcMuHANyxrwZf7e81/vMuuQ+A1+evB+DfvxoGwOCD/xiO/eRBGnw165NvANjzNDWWt52n13zgQy2O8ugJewCwzRctWTB+LgBdj1c7S6DLD2yfE449Ly8TgBWTZwLQ47B9AFhSqPNdL3kJ73v2Cg3G6uw19c3riwBo2VX1+aBgCkDLbhoUVl7qv/3ld0wYa7MPnAqCs9YWqoYfFlHxwVhBwrX1W2PJ0QJNP9Dwg3bhJp9QzevzZaWqAAZFU6IJ15IGZ4UJ1CLtaIK1SHRWVJNOXkSFCteNZ0ck6Orq1jUhc9dG0RRjOziX6lN8isO514HXI31Xx70uApK6wDvnbgRurLHJkLodaiKQIyLdgLeB3wCP1eREDMMwGgriylPaGiOpLvrinNsK/By41zn3CzRgwDAMo4nhoLw0ta0Rkmo+fRGR/YFfo9FjoPqUYRhG08JRo/JOQyPVRf8CNAL3RW9c6AuMr7VZRWi7x0BuvvX9sP3OEo0T23fUZQCM20919M+PUN/66SWDADjwpQcAOKhETRO/37QWgFyvDw9a+C4AC/rF6r0Xel/ztXOnAtD15j8B0O+lTQB88bn61GcNWQVAhvff//Zb1dcP3LMLAKVeiM1ZGnNy6tK/LQArpmrytl3+oDaF1SX6xLB0s+rqWf7cGcs2AjA0Rz9ft2z0hdG7t9ZrzNkSjp3ZcRcAXPlCAMpyExOsbSzR95URFEmJFE1Zs1n191gR9Dg//axEP/2cFlkJ7TDBWmnyBGvRBGyQTMOvohB6pB2cH5CK1l4x4dr2E6ylklsl6stf1TmNNR1v88JBeTNf9J1z7wPvi0hLEWnpnJsL1EmGTcMwjLqmser1qZBqYfQhIvIV8A3wrYh8ISKm6RuG0TSpOT/9Bkeq8s4DwJ+dc+MBRGQE8CBwQO1MyzAMo55wDlJPw9DoSHXRzwsWfADn3ASRiFO5YRhGE6EpyzupLvpzReQq4AnfPhmYWztTqsi0BWt5/oLYl4qtl/wKgO77qCPRvjf/HYDz8/cCIP+4/wPgki/VavaLOy8BoP+hlwLw4zQ1rk665F8A3H92r3DsI9uqIfNh356Z0w+A0w9Ro+o5r2hCthWvarWr/O5DAJg/+VUAfjK4EwCfBNWtJr8bjt15bzU4f/aUXt91V4NzYZkGcs1crYbZoFrXipXabttO51S8QY3HrXbXa2ybtjkcO6NTT/9Kk7mV52kCtrBSlg/OSsvQALF1PjgrwxtuNwRtb4QtLoxVzsrMTgzOatXGB2NFEqwFhtog8KpsO8FZ0QRrmWmJRtWwXRZNyJaYcK2yKllQdaWsHaGmE6w15gpNjXjqVVCzwVkNjeoURu8AvAD8D2jv+wzDMJoezVXTF5Ec4GygHzANuMg5t2175xiGYTRqajgNQ0OjKnnncWAb8AFwDDAQ9dk3DMNokgjNW9Mf5JwbAiAiD1MDaT13hPLSbbz087+F7e8OPgyAyZu0YMnIu1XHvtoHP+36Z61GdsONWuAk7QMtXHPvQ/sBsO/RZwNw3THXATC+19Rw7Ot+owFTbZdqgrXb3/8egNt+MgCA09dpYNXsV7RmfLcf/xyAzWP0j2QfnwxtVUvVzpd+8FU4duf9tajLvAe1Hs3GnPYJ73P6UrUbdMjSX0tQNCUIxir2wWWtenby92VZeK607ZIwVhCMFSRUW701sUjK6s3FAGTk6nyDBGtZ3hYR6PdQeYK10hIdM9fPNwjOihZRSarpR4KrMtOj7eolWItvVqbzRyXoqoqm1JdmXRsJ1mqjaErTxUFZ0/XeqUrTD6Wc6hZREZEeIjJeRL4VkW9E5Hzf31ZExonIbP+zzQ7M2zAMo3YI0jA0UU2/qkV/TxHZ6LdNwB7BaxHZWMW5pagNYBCwH/AnX939cuBd51x/4F3fNgzDaDA05SybVeXT3+Gkaj4X/zL/epOIzECL+o4CRvjDHgcmAJft6HUMwzBqluZtyK0RRKQ3MAz4DOgUV5xlOdCpknPOAs4C6Nq9B1dccHO4b+LhfQD48oARAExKV6185MTnATh8rWr4V65bAcQSmO07/zUA5g0+DoAN27SOwaqZsYLzvf6unz8DX9YvMhMmaDhCXp8FQCzB2vRvVV8fOVyLmxf5a+Qt/hKAHgNVr1/86aJw7N5nngHA6pJHAZi/viRhflMXrQfg5JygaIr66Rf0UQVs20ydU1a3gQC48sXh2GWttIhKZQnWVnvNvrIEa+t9OzMn8MmPqXktWmcDVSdYC9sRv/2cjESNHyr63Qd++UHRlOomWEupMHodJFiLDlFhv2nrjYMmvOjXdKxJBUSkJerbf4FzLkES8nUgk9Ylc86Nds4Nd84Nb9uufbJDDMMwap4gDUMqWyOkVhd9EclEF/wnnXMv+O4VItLF7+8CrKzNORiGYVQPhyvdltK2M6Ti1CIiQ0XkE+8M87WInBC37zERmSciU/w2NJXr1tqiL/o99mFghnPu9rhd8ZXfTwFerq05GIZhVBtHXT3pp+LUshX4rXNuMHA08C8RKYjbf4lzbqjfpqRy0drU9A9Ea+lOE5FgMn8BbgaeE5HTgQXAL2txDoZhGNXC4cKcT7VMlU4tzrnv4l4vFZGVaEqc9Tt60Vpb9J1zH1J5HMlh1RmreNYs9rrqH2G78+9/AMBN7dWA2+1MrZh1zBi1D198x4UADD9bv2D8ostsAMafeQcAt5zbG4CLOrcC4FFvzAR4f1tXHePIzgAc/5yqUguf0rHb9dOAsO8+fwWAU4ZqErX3cjUYa9MHbwDQ/QCtZPXe6JiR+IBeQ4FYgrWpK9TE0dYbPj9brgnUOnRWY3GRDwRrPdxX45qqwVqZXXv7ET8Kxy7N1cC0IBhrXaGvjJWVA8QMuZneEL12S2IwVok33AaBWMmCswJDbqscH4y1LTEYKzDC5kaCs6LJ1aBigrXQyJpigrWooTdZwrWKRtRoe/tG1Vo3eNUStRGI1azsz47qVM5qLyKT49qjnXOjUzw3JaeWABHZF8gCvo/rvlFErsZ/U3DOFVd10Trx3jEMw2g8VCuf/mrn3PDKdorIO0DnJLuuTLiic05Ekjq1+HG6oFmOT3EudC26Av2wyAJGo98Srq9qwrboG4ZhxOPcThtpY0O5wyvbJyIrRKSLc27Z9pxaRKQ18BpwpXMulA7iviUUi8ijwMWpzKmxfoM1DMOoJRyuvCylbSep0qlFRLKAF4H/OOfGRPYFXpACHAdMT+WijeJJf2NRKdMPXR+2d7lA3/v7vrDKuZceCcDex2qRlH5z1wHwyh9U+2/5qzsBeKjHMQBMfXMCAIfcrMVWun22Zzj2dS9/A8C4U3cFYNuWDQDMfOFbHfuiPwJQ8l/9JjakleraK9urXWD+W5pMbcDvjgXg+zsmhmMvK2uR8L4mzdd5DvMa+fpVGozVpm8BAEW+aEp+Py3yUl6qtgnXtjtR1hV5bTxTNf0VWxKDsVZtTEywtsYnXMsMNH1vAwjaWzbGpMFcP7/SEu2LJliLBmtFE6zlpCcroqJ95RHdP9wfCcZKT0seFBWMmUxzrq4MnYpuXd1grOqOl4zmJKc3CALvndonqVOLiAwHznbOneH7Dgbaicjv/Hm/8546T4pIB/RPZAqaBr9KGsWibxiGUXe46hhyd/wqzq0hiVOLc24ycIZ//V/gv5WcP3JHrmuLvmEYRjyOunLZrBds0TcMw0igWt47jY5Gseh3G9Cdqw65JGyv3VeLpMz+678AGPCvcwFov+vBABy6QHX01Zf/DoAHf6GF03t4X/rNK+YDUPKzuwH4VaeF4dj33P0SAIUF7wDQqov62386430AzjykLwDTAx3b++v3OlgLk899R8cefLvOZW3JLeHY01YmFj7/dIFq+sfma0KzzavVeN9mgPrll0xUP/7MnuoR5spnAlDWWj3AAp98gPVe0w8Kna/c4jV775e/clPQVr/9TV7zz87VP4HiIvVWKOiQB0BpSeyPPuqXX1mCteDpKKrhZyTR9LOjRVPSEo+pmBxt+wVOkmnj1U2wFt1fE8nRGmuCtUY67ZqhBr13GiKNYtE3DMOoO+xJ3zAMo/lQd9479YIt+oZhGHE4XELKkKaGLfqGYRjx2JN+/TNrcwZ/750XtjvddA4AJ51/PwCnvfsBAE/OvA2A/U5Xg+11x1wHwBMbPgTg/bP2AeCupfrz0tdmAXDbTwaEY990uSa1++q+GQD0+fG1AKx640E9Z0A7ANK98XXx2LcA6HmUjvniGDW27p+v1b3K4rJpfDpfq211zdH5rVmmCdba9tdkaYU+wVrbIzUYq+wdjbJO69wn4X5sKNNfW7whd5kPtsrI0fu0bEMRAJl5+QCs3KjtbH/toi1qqAqCsYrWajK3bN/eVlwSjt3Sn1NWoscEht2ySoKzssNKWfq0lJNRMfA7TKhWVklwVnpyw22lht0KV6g6wVp9GCtrIxirNhKsNWucw20rqfq4RkqjWPQNwzDqjroJzqovbNE3DMOIYvKOYRhGM8G5mkim1mBpFIv+1nVr6T8lVqdgv5c14OnGNA1E6t1CNefd/qca/stHXwFAumh7xXQN1ur24QMA/OQ1rUHwyvOq9f87891w7BbttIjKRx+rneD0u1Xvn3+T6tLZX2kw1oAf9gBgzhuaBK3PRVrpbEXxowBMXaGBWC3j9OxPZq8G4MKWqsVvWKHtDrtrMFbxJA3WyumnieJc+WIAStvotSRNtfK1PhAr0ydPA1gWBF/5vmXrVcPPaqEa/1qfQC0rCMYqVE2/dVu9h2t8EZWWgV5fXBiO3TI7McFay0iwVl5mYtGUbP+eg+ODginl8QnXIsFY0Xa0SEoklqtCO17XTjUYK0pU8092fFUJ1hprMJaRiHnvGIZhNBecw5XZom8YhtEscM5Rvq20vqdRa9iibxiGEY/DnvTrm67dOzP85DvC9mnvPgXA8zM+A+DA+arDX/fjGwB4YtreAEz4vfrOP7xcf/7xlTkA/OPHqtM/dtNdAEy+dWY49i5HXg3Aonc1hfU5Q7RW8ZsFmqhs4dNawGWXUftr/5tPArBP+90AKClXx/z3vH7fNSd2i99cqAVZOgxuD8CWVZrorf3IfgCUTlS//PSeA/0ZbwOwEb12uk+mtnhjok8+wMJ1WwHIaqU+/8s2eL9772NfuDlIsOYLuHu//BzfDvzyC1qovSHwyYed98sPNP74dLU17ZeftIhKFX75dVE2rko7wg6NaYXPaxtb9A3DMJoJzjnKLZ++YRhG86Epe+9YYXTDMIx4vPdOKtvOICJtRWSciMz2P9tUclyZiEzx29i4/j4i8pmIzBGRZ30R9SqxRd8wDCOOwHsnlW0nuRx41znXH3jXt5NR6Jwb6rdj4/pvAe5wzvUD1gGnp3LRRiHvtN2wDNemc9jep40aNnv+608A3HPCTQC09gbDIBirYOIjAJz5sRpMg6pYt2/5HxCrijXuvffDsS+6f3cApt+qxsnsj9RoPORoPXbmC5qIrffl1wCwqPAxAD5ZvAmIVcX64NsVAFzeLjcce92SpQB02kurbBVNVGNvzm6HAHHBWO16A7GEaiu36B9XEHi10Btps3wyNYDF63yfD8Za4xOu5eT5BGtbvaHWV8Zas0znW+AD24JgrGggFlQ/GCuoilVeSeBVsr4dDcaqLBBLj4m0I/urCsZKZttsKsFYjXTadUZ53RhyRwEj/OvHgQnAZamcKPqHNxL4Vdz51wL3VXWuPekbhmHE4102U5R32ovI5LjtrGpcqZNzbpl/vRzoVMlxOX7sT0XkON/XDljvnAu+biwGuqVy0UbxpG8YhlFnVC8id7VzbnhlO0XkHaBzkl1XJl7SORFxSY4D6OWcWyIifYH3RGQasCHVCUaxRd8wDCMOR8157zjnDq9sn4isEJEuzrllItIFWFnJGEv8z7kiMgEYBvwPKBCRDP+03x1YksqcGsWiv2zFJhY++tuwnbHxSADO7TQCgGdmapKzpY+cBsBjHw8C4Nh7PgVgwml9AbhpsRZIef+vnwMw7EotwhIUSAG4qpcqXm27twZgxr3PAjDw7OMBePo5TfY2OKdnwhzHTtNvacPzVId/af56ALrsHfuQD4KxOv58MAClb2tQWFrvPfwRr+l8SlQzT89We8C89aq3Z+bpnOau0mRuQSAWwILV2pfjg6sKN6m+nuPns3aFFmxp4YOxSgp1zHx/fGmR7g80/tK44KxQ0/eafYvMIDhrW2K7PLEgShCMlayISlZGcg2/Mo2/qmCsZNp6Vbp1VRp+KgVPqhozSkMJxjK2g3OUl9RJGoaxwCnAzf7ny9EDvEfPVudcsYi0Bw4EbvXfDMYDxwPPVHZ+MkzTNwzDiMdBeXl5SttOcjNwhIjMBg73bURkuIg85I8ZCEwWkanAeOBm59y3ft9lwJ9FZA6q8T+cykUbxZO+YRhGXeGomyybzrk1wGFJ+icDZ/jXHwNDKjl/LrBvda9ri75hGEY8LjFPVFOjUSz6nTu1ZEz3YWH7zj/9C4B/7q3FR57y2vL/+v8GgGcOUn/2/Y7TWIdZ0xYB0OMHqvm/Nfo9AO75pWrp467MDsde/4hq9nuecQAAL92iBVYGPXkSAKuK/w7Aa2FCNdXAX5imRc1P3lV19rULtbhKtxGDwrGLnvJ++Xse43tU0y/M7w7EEqotDAqetFAN//u1Xq9v3QGAuatUf89tFUu4tnFDse9TjX6rT7DW0dsmSnzRlHa+gEtpoY7Rzmv+gYaf7zX98rjC0K2yAk1fx8iN+OnnRBKqhe2oxh/np1/BL78Kn/n0tMQxqjoeqvbL3xHqwi/fEqrVN87SMOwIIvKIiKwUkelxfSmFHRuGYdQb1fPTb3TUpiH3MeDoSF+qYceGYRj1gnOOspLSlLbGSK0t+s65icDaSPcoNFwY//O42rq+YRjGjqHyTipbY6SuNf1Uw47x4cxnAXRtlQcp5Y8zDMPYSaxyVu1QRdgxzrnRwGiAHrsNcUsWFYX7vh6rAVNDJqqR9UKfUO3Ca7Ta1ffHqZEyr0MPAJ793zgA/vbJDwCY/qgaIntNeR6AkaN2Dcf+/HY18h79+TN67JUaMDVuoVamChKqPf/xAgAu79gCgHvn6Bx6jugPwJaJajzO3++QcOzy/+hY27pqUrcgodrCDWogDRKozQwCrfLVcDvTJ0fLyVcTyNI1Ope81jED9GafhC1IqLZ+pY7R3h/z3RYdo22etssqMdy2TpJwLTczsVJWNBgrSLAWJmBLTzT0BsnV4qkQjBVNsFZFQrUKht4UKmdVNxgrFaNtbQRj7SxmtN1JHLiySpemRk9dL/ophR0bhmHUFw5XV1k264W6jsgNwo6hGmHDhmEYdYYDV+5S2hojtfakLyJPo7mi24vIYuAaNMz4ORE5HVgA/LK2rm8YhrEjOAdlJRacVW2ccydVsqtC2HFVLFm0nItnTQjb77y0DoDhF70OwKxTVcT85zotXPLYhdp/1tMvArDhLU1jcULuPAD6HKjBUJ9cNhqAg5/4ezj2g0+dAUAXp6mps7xo+8AHcwE4pY0GUD3zjRZE6XukFlfZOFOTuXU+9WAASt/+SAccsH84tqS9CcCiQv2CFWj401aq3p6d3x6A6Us2ApDjC8d8t1TbLQu0eMymtarHt4jT9Fcu1EyrvftqcNjcLWrX6NBKz9m2Vfd39Ods88FZbXzCtUDjjxVR2RaO3SorUcOPBmMFGn9ANJlaht+dSnBWLPiKxP0R8TyVhGuNQcO3ZGoNEOdM0zcMw2hOlNuibxiG0Uwwl03DMIzmgwPKG6mRNhVs0TcMw4jHOTPk1jctCtoy5Lbvw/b0MzVzZMsnxgPwxI81SOvX92tA1XcnqgH3rsEaTPTRcM3G+ekZfwFg3zsuAeCKAy4AoH27WInLQMq79V01zI7yhtuXJmslssE/UsPturlTAeh16REAFF85CYD0YdqWNK3atbi8VTh2YLidutwHW7XRgOQvF64HIK+DVuP6epG2W7fVwK8NPhirZb7OZbU37PboVRCOveCbxQB0KegDwLYtyQ23bfMSDbf5OYmG25Y+o2ZZXHBWYKiNGm4Do2tguI0FY20/I2byYxL3V2W4TSXL5s5Wwkrl+IZguDVbcM3iLDjLMAyjGWGLvmEYRnPCInINwzCaD3UUkZtKfREROVREpsRtRSJynN/3mIjMi9s3NJXrNoon/QGtS5k5aXzYvvthDb66wAdfTT1W2/ftoVr55yN6ATDxZ78HYsFXFw/VwKuczhpAVeb0l/aXV4I6w3BKe9XRL5o4B4Drf7YbAKtnqkbf56+jACi6TIOv0vY7HwBJ+xKABejvLbuVBkl97gOtAHLbdQXgo7macTrQ8L+Yp+18f+11K1R/b91ONfwg8Kp7D7UJLJyh+n33Nn3CsT/dtNb36TklXtPv1FqDswINv02uT7DmNfz87EQNPwjEii8XF+j8YaWszMQEa1mRylgZETE8qt9DzWv4yWTtqoKvqkrIlgzT8Js+jjrz0w/qi9wsIpf79mUJc3FuPDAU9EMCmAO8HXfIJc65MdW5aKNY9A3DMOoM5yivG++dUWiqGtD6IhOILPoRjgfecM5t3ZmLmrxjGIYRh3P6pJ/KtpOkXF/EcyLwdKTvRhH5WkTuEJHsZCdFsSd9wzCMCNWoitVeRCbHtUf7WiAAiMg7QOck512ZcL0q6ov4VPRDgLfiuq9APyyy0NojlwHXVzXhRrHoL5m1mDHfxsrpThr2CgBXFamWv+SsvQEYc7Bq+D+fpsVKzu18KACrygcCkOsrdZz3pOrvV/dV/f3Ud6eEY9939gF6ztuq4e9y9+kAFJ/xPz3goBMBSMtQv/yZRVq0JNf73L/r9fqWnXoDMG5GrGRAflfV4L+YsxqAtp1aArDG++0HBVAWz14DwID+7QCYN0WTvfXt0A+AjzesAqCXtwFATMPvkq8afmmRL6Lii6SUlWgRmjY5vu01/NBPf1ukHeenHyZYq0TDz6xCw09W4CSq4VfQ+HeyAApUnUCtNgqg1ISGXzGZ3E4PaVQHV62n+NXOueGV7XTOHV7ZPhGpTn2RXwIvOufCTIhx3xKKReRR4OJUJmzyjmEYRjzeTz+VbSepTn2Rk4hIO/6DAtGnm+OA6alctFE86RuGYdQVjjpLuJa0voiIDAfOds6d4du9gR7A+5HznxSRDuiX0inA2alc1BZ9wzCMeJyjrKT2F33n3BqS1Bdxzk0Gzohrzwe6JTlu5I5c1xZ9wzCMOJyDcmdpGOqV1tkZdLzk5LB92Stq+L7uxzcAcNriKQBMfGAIAG+PXw/AAW3UqHnlA58BMGbUrgDc8/Y7APzwpl8BsPqGSeHYne7UsUvH3gjA0j6HAJCZp+e8PV+Nrq26auK156ZqBa38noMAePkrTczWrpdPnjZrVTh2Rx9ctXKxBmz1G9hBj/lUK3rtO1SDt2Z9PA2A/p10zLc3rvJtNfwGydS6+cAriBluO+ap11apD8ZqH1TG8obatkFwlm+3yo4EXkWMtgDZkYRqWRELaFbEcBsNzspIYsmtKjiromE3sZ1K1avoMVUZg1Oxl0YNtTtruDUjbcOkzBZ9wzCM5oEjlm23KWKLvmEYRgR70jcMw2gmlDsoscpZ9Uv2gAE88trssF3066EAHJCn+vQx16rePuZ4DcI65CENpPr3g2oA/8MNGsw16I27ASg8RvX61YdqUZXMO64Kx35jrQZI5ffUsUZ/tgiA9rvuA8D9EzVQqvMA1dvf+lz3d99Vg+7mzdLAq6heD3DU0XrOK19ogre9jlYbwyevqCfWsJ4aGPa8D74a0FE1/JJN6wDo4YuolGxVm0CCpl+sGn4nXyQl0OzbtggSrAUafnpCOzei4Wcn0d9zIsFYWemJ50Q1+8xI9Ec0eAsq6v7V1eyjNoBUiqhUJZ/XtF4PFmjVWDF5xzAMo5ngcCbvGIZhNBfMkGsYhtHMsEW/npkxbwUfPXx62O7wj3sBGP3VswD84bg7AegyQWsJlBx9BQAf76EFTlp10aR3t36jGnTnPTUR24UvfQNA731jgW1/f0HTV+yyzzAAXhynxVR2G66FWb6drBr+YYerHv/Gi5qY7bTfjQDggftfBeDs43cH4MMxb4Zj/7CfFm95do369u/dowCA4g1qBxjQXu0JxV7D7+sLowdFzXv6ZGplXr/v4PV7iBVJKYgkTGsZKXjSItKOavq5mRX99LMignu0HdXsq9LrIYlfflXtHfCxr0qj3xHNviqN3jT7xo9z5r1jGIbRbHCY945hGEazwTR9wzCMZobJO4ZhGM0E1fTrexa1R6NY9NMyMjk7/adhu89Bagg95BmtUrXncVrN6rAbJwCw/0m/AOD3t00E4Ee/OgqAex/S/b89+SAAHhqtFbauuPjn4dg33PgkAHfceCoA511yn/afdq6e+8yLAJx0mRp/n75zhl5j4C8BuG35fJ1b77YAFK5bEY69d9fWABRv0nkP9IbboOpV7wJvqPVG2a6tshLa7XITjbRtctLDsQPDa352oiG2ZVZ6QjsvEjmVm5FoecxJYnXNzkg8p0rDbvr2DbtQdaWsipWzqm+Ura7R1YyyRoA96RuGYTQTHFAnJVTqCVv0DcMw4nA4894xDMNoLqj3ji369cqQXm0Zc8d9YXvjx/cA0PqAPyVtT4q0H7zDt2/ToK5rRv4GgNv+qnr8H4d3Dce+fMV8AE4Y1B6AM9ctB+CYXQqAmB5/UHdNhlZapIFTe3XSQKpAf9+trRYzCfR3gL75icnPerRKLGDSNS+x3TE3ptkDtMtJ1NbbZFesa986K7GvVWaiMJ0X0fBbpKLpp22/HblEhXZGEm082peGq9E2gET+cXe2XRtj1sU1GsuYNXGNGqGJG3Irrhp1gIgcLSKzRGSOiFxeH3MwDMNIRvCkn8rWGKnzJ30RSQfuAY4AFgOTRGSsc+7bup6LYRhGMpryk359yDv7AnOcc3MBROQZYBRgi75hGPVOOU07DYO4Ov6KIiLHA0c7587w7d8AP3DOnRM57izgLN/cHZhepxPdMdoDq+t7EinQGObZGOYINs+apibm2cs512FHTxaRN/08UmG1c+7oHb1WfdBgDbnOudHAaAARmeycG17PU6oSm2fN0RjmCDbPmqYhzLOxLeLVpT4MuUuAHnHt7r7PMAzDqGXqY9GfBPQXkT4ikgWcCIyth3kYhmE0O+pc3nHOlYrIOcBbQDrwiHPumypOG137M6sRbJ41R2OYI9g8a5rGMs9GS50bcg3DMIz6o16CswzDMIz6wRZ9wzCMZkSDXvQbaroGEekhIuNF5FsR+UZEzvf9bUVknIjM9j/b1PdcQaOgReQrEXnVt/uIyGf+vj7rDer1PccCERkjIjNFZIaI7N8Q76eIXOh/59NF5GkRyWkI91NEHhGRlSIyPa4v6f0T5S4/369FZK96nuc//O/9axF5UUQK4vZd4ec5S0SOqqt5NmUa7KIfl67hGGAQcJKIDKrfWYWUAhc55wYB+wF/8nO7HHjXOdcfeNe3GwLnAzPi2rcAdzjn+gHrgNPrZVaJ3Am86ZzbDdgTnW+Dup8i0g04DxjunNsddUQ4kYZxPx8Dov7lld2/Y4D+fjsLuI+64zEqznMcsLtzbg/gO+AKAP8/dSIw2J9zr18XjJ2gwS76xKVrcM6VAEG6hnrHObfMOfelf70JXaC6ofN73B/2OHBcvUwwDhHpDvwYeMi3BRgJjPGH1Ps8RSQfOBh4GMA5V+KcW08DvJ+ox1uuiGQALYBlNID76ZybCKyNdFd2/0YB/3HKp0CBiHSpr3k65952zpX65qdo7E4wz2ecc8XOuXnAHHRdMHaChrzodwMWxbUX+74GhYj0BoYBnwGdnHPL/K7lQKf6mlcc/wIuJVYMqB2wPu6frCHc1z7AKuBRL0M9JCJ5NLD76ZxbAvwTWIgu9huAL2h49zOgsvvXkP+3TgPe8K8b8jwbLQ150W/wiEhL4H/ABc65jfH7nPrC1qs/rIj8BFjpnPuiPueRAhnAXsB9zrlhwBYiUk4DuZ9t0KfPPkBXII+KUkWDpCHcv6oQkStR6fTJ+p5LU6YhL/oNOl2DiGSiC/6TzrkXfPeK4Guy/7myvubnORA4VkTmo/LYSFQ7L/DyBDSM+7oYWOyc+8y3x6AfAg3tfh4OzHPOrXLObQNeQO9xQ7ufAZXdvwb3vyUivwN+AvzaxYKHGtw8mwINedFvsOkavC7+MDDDOXd73K6xwCn+9SnAy3U9t3icc1c457o753qj9+8959yvgfHA8f6whjDP5cAiERnguw5DU203qPuJyjr7iUgL/zcQzLNB3c84Krt/Y4Hfei+e/YANcTJQnSMiR6MS5LHOua1xu8YCJ4pItoj0QQ3Pn9fHHJsUzrkGuwE/Qq353wNX1vd84uZ1EPpV+Wtgit9+hOrl7wKzgXeAtvU917g5jwBe9a/7ov88c4DngewGML+hwGR/T18C2jTE+wlcB8xEU30/AWQ3hPsJPI3aGbah35xOr+z+AYJ6xn0PTEO9kepznnNQ7T74X7o/7vgr/TxnAcfU9++/KWyWhsEwDKMZ0ZDlHcMwDKOGsUXfMAyjGWGLvmEYRjPCFn3DMIxmhC36hmEYzQhb9I16R0TKRGSKz145VUQuEpEd/tsUkb/Eve4dn9HRMJo7tugbDYFC59xQ59xg4Ag0C+Q1OzHeX6o+xDCaJ7boGw0K59xKNN3vOT5iNN3nW5/k863/HkBERojIRBF5zedav19E0kTkZjQL5hQRCXK4pIvIg/6bxNsikltf788w6htb9I0Gh3NuLpqrviMasbnBObcPsA9wpg/JB02zey5ab2EX4OfOucuJfXP4tT+uP3CP/yaxHvi/OnszhtHAsEXfaOgcieaJmYKmr26HLuIAnzutt1CGhvcfVMkY85xzU/zrL4DetTZbw2jgZFR9iGHULSLSFyhDs0IKcK5z7q3IMSOomCq4spwixXGvywCTd4xmiz3pGw0KEekA3A/c7TQx1FvAH3wqa0RkV19gBWBfn4U1DTgB+ND3bwuONwwjEXvSNxoCuV6+yUSLaDwBBCmrH0LlmC99OuNVxMr+TQLuBvqh6Y1f9P2jga9F5Es0S6NhGB7Lsmk0Sry8c7Fz7if1PBXDaFSYvGMYhtGMsCd9wzCMZoQ96RuGYTQjbNE3DMNoRtiibxiG0YywRd8wDKMZYYu+YRhGM+L/ARlCzDGxoGocAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 문장의 길이 50, 임베딩 벡터의 차원 128\n",
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "  # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 스케일링\n",
    "  # dk의 루트값으로 나눠준다.\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Query, Key, Value인 Q, K, V 행렬 생성\n",
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 함수 실행\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값\n",
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    # d_model을 num_heads로 나눈 값.\n",
    "    # 논문 기준 : 64\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    # WO에 해당하는 밀집층 정의\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "    # q : (batch_size, query의 문장 길이, d_model)\n",
    "    # k : (batch_size, key의 문장 길이, d_model)\n",
    "    # v : (batch_size, value의 문장 길이, d_model)\n",
    "    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 2. 헤드 나누기\n",
    "    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 4. 헤드 연결(concatenate)하기\n",
    "    # (batch_size, query의 문장 길이, d_model)\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 5. WO에 해당하는 밀집층 지나기\n",
    "    # (batch_size, query의 문장 길이, d_model)\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, key의 문장 길이)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': padding_mask # 패딩 마스크 사용\n",
    "      })\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 포지셔널 인코딩 + 드롭아웃\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 인코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "  # 룩어헤드 마스크(첫번째 서브층)\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  # 패딩 마스크(두번째 서브층)\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "      })\n",
    "\n",
    "  # 잔차 연결과 층 정규화\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "          'mask': padding_mask # 패딩 마스크\n",
    "      })\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 포지셔널 인코딩 + 드롭아웃\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 디코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "  # 인코더의 입력\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 디코더의 입력\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더의 패딩 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 디코더의 패딩 마스크(두번째 서브층)\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 다음 단어 예측을 위한 출력층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9000, 128)\n",
      "(1, 9000, 128)\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실 함수 정의\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#학습률\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 926\n",
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n",
      "['가리비 구이의 칼로리는 몇이야 ?', '가리비의 칼로리는 몇이야 ?', '가쓰오부시의 칼로리는 몇이야 ?', '가오리의 칼로리는 몇이야 ?', '가자미/넙치 요리의 칼로리는 몇이야 ?']\n",
      "['(1개)당 - 칼로리: 17kcal | 지방: 0 . 50g | 탄수화물: 0 . 38g | 단백질: 2 . 63g', '(1개)당 - 칼로리: 35kcal | 지방: 1 . 75g | 탄수화물: 1 . 68g | 단백질: 2 . 90g', '(100g)  당 - 칼로리: 340kcal | 지방: 2 . 26g | 탄수화물: 2 . 34g | 단백질: 76 . 80g', '(100g)  당 - 칼로리: 84kcal | 지방: 0 . 88g | 탄수화물: 0 . 17g | 단백질: 17 . 60g', '(100g)  당 - 칼로리: 133kcal | 지방: 4 . 24g | 탄수화물: 0 . 41g | 단백질: 22 . 00g']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "# train_data = pd.read_csv('ChatBotData.csv')\n",
    "# train_data.head()\n",
    "DATA_IN_PATH='ChatBotData.csv'\n",
    "train_data=pd.read_csv(DATA_IN_PATH,encoding='utf-8')\n",
    "print('챗봇 샘플의 개수 :', len(train_data))\n",
    "print(train_data.isnull().sum())\n",
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", str(sentence))\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)\n",
    "\n",
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [2067]\n",
      "종료 토큰 번호 : [2068]\n",
      "단어 집합의 크기 : 2069\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임의의 질문 샘플을 정수 인코딩 : [1538, 6, 9, 11]\n",
      "정수 인코딩 후의 문장 [1538, 6, 9, 11]\n",
      "기존 문장: 갈치조림의 칼로리는 몇이야 ?\n",
      "1538 ----> 갈치조림의 \n",
      "6 ----> 칼로리는 \n",
      "9 ----> 몇이야\n",
      "11 ---->  ?\n",
      "질문 데이터의 크기(shape) : (926, 40)\n",
      "답변 데이터의 크기(shape) : (926, 40)\n",
      "[2067 1560  376    6    9   11 2068    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[2067 1851   20 1852   13   12    7    1  417    2    8    1 1859    3\n",
      "   30    2    5    1 1859    3   57    2   10    1 1861    3  145 2068\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))\n",
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))\n",
    "\n",
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))\n",
    "\n",
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)\n",
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2067 1851   20 1852   13   12    7    1  417    2    8    1 1859    3\n",
      "   30    2    5    1 1859    3   57    2   10    1 1861    3  145 2068\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[2067 1851   20 1852   13   12    7    1  417    2    8    1 1859    3\n",
      "    30    2    5    1 1859    3   57    2   10    1 1861    3  145 2068\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[1851   20 1852   13   12    7    1  417    2    8    1 1859    3   30\n",
      "     2    5    1 1859    3   57    2   10    1 1861    3  145 2068    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
    "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyper-parameters\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 4s 23ms/step - loss: 0.0214 - accuracy: 0.7006\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0192 - accuracy: 0.7013\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0179 - accuracy: 0.7015\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0171 - accuracy: 0.7016\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0160 - accuracy: 0.7019\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0153 - accuracy: 0.7020\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0147 - accuracy: 0.7021\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0139 - accuracy: 0.7023\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0132 - accuracy: 0.7023\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0128 - accuracy: 0.7024\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0131 - accuracy: 0.7024\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0126 - accuracy: 0.7025\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0117 - accuracy: 0.7026\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0112 - accuracy: 0.7026\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0115 - accuracy: 0.7024\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0110 - accuracy: 0.7027\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0105 - accuracy: 0.7024\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0105 - accuracy: 0.7025\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0103 - accuracy: 0.7024\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0101 - accuracy: 0.7024\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0092 - accuracy: 0.7026\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0095 - accuracy: 0.7024\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0091 - accuracy: 0.7026\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0084 - accuracy: 0.7027\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0086 - accuracy: 0.7026\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0085 - accuracy: 0.7024\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0084 - accuracy: 0.7025\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0077 - accuracy: 0.7026\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0076 - accuracy: 0.7027\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0077 - accuracy: 0.7025\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0072 - accuracy: 0.7026\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0073 - accuracy: 0.7026\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0071 - accuracy: 0.7026\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 0.7025\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0071 - accuracy: 0.7024\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0071 - accuracy: 0.7023\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0069 - accuracy: 0.7024\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0065 - accuracy: 0.7024\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0066 - accuracy: 0.7023\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0061 - accuracy: 0.7025\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0064 - accuracy: 0.7023\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 0.7026\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0053 - accuracy: 0.7025\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 0.7022\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0055 - accuracy: 0.7025\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 0.7023\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 0.7024\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0053 - accuracy: 0.7023\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 0.7021\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0046 - accuracy: 0.7025\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0050 - accuracy: 0.7024\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0045 - accuracy: 0.7025\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0047 - accuracy: 0.7024\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0047 - accuracy: 0.7024\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0043 - accuracy: 0.7026\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0045 - accuracy: 0.7023\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0043 - accuracy: 0.7026\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0046 - accuracy: 0.7023\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0046 - accuracy: 0.7023\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0076 - accuracy: 0.7015\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0073 - accuracy: 0.7014\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0063 - accuracy: 0.7020\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 0.7023\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 0.7021\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0037 - accuracy: 0.7025\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0039 - accuracy: 0.7025\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 0.7024\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0036 - accuracy: 0.7025\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0038 - accuracy: 0.7024\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 0.7024\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0053 - accuracy: 0.7019\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0060 - accuracy: 0.7018\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0055 - accuracy: 0.7018\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0048 - accuracy: 0.7021\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 0.7022\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 0.7021\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0048 - accuracy: 0.7022\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0046 - accuracy: 0.7022\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 0.7022\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 0.7021\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0043 - accuracy: 0.7022\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0038 - accuracy: 0.7022\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 0.7020\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0052 - accuracy: 0.7020\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0060 - accuracy: 0.7015\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 0.7018\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0049 - accuracy: 0.7018\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0046 - accuracy: 0.7019\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0048 - accuracy: 0.7021\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0051 - accuracy: 0.7020\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 0.7015\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 0.7021\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0078 - accuracy: 0.7013\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0065 - accuracy: 0.7014\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 0.7020\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0048 - accuracy: 0.7018\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 0.7020\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 0.7022\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 0.7022\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 0.7017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f28ed0c9588>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "EPOCHS =100\n",
    "model.fit(dataset, epochs=EPOCHS)\n",
    "\n",
    "#model.save('/content/drive/MyDrive/ChatBot/chat_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Layer PositionalEncoding has arguments in `__init__` and therefore must override `get_config`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-e77ae793b255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_name.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2112\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m   def save_weights(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    145\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    146\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 147\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    148\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mmodel_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   metadata = dict(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1353\u001b[0m           \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m       \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m       \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    506\u001b[0m         return serialize_keras_class_and_config(\n\u001b[1;32m    507\u001b[0m             name, {_LAYER_UNDEFINED_CONFIG_KEY: True})\n\u001b[0;32m--> 508\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0mserialization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1353\u001b[0m           \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m       \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m       \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    506\u001b[0m         return serialize_keras_class_and_config(\n\u001b[1;32m    507\u001b[0m             name, {_LAYER_UNDEFINED_CONFIG_KEY: True})\n\u001b[0;32m--> 508\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0mserialization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m       raise NotImplementedError('Layer %s has arguments in `__init__` and '\n\u001b[1;32m    720\u001b[0m                                 \u001b[0;34m'therefore must override `get_config`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                                 self.__class__.__name__)\n\u001b[0m\u001b[1;32m    722\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Layer PositionalEncoding has arguments in `__init__` and therefore must override `get_config`."
     ]
    }
   ],
   "source": [
    "\n",
    "model.save(\"model_name.h5\")\n",
    "\n",
    "# /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in get_config(self)\n",
    "#     719       raise NotImplementedError('Layer %s has arguments in `__init__` and '\n",
    "#     720                                 'therefore must override `get_config`.' %\n",
    "# --> 721                                 self.__class__.__name__)\n",
    "#     722     return config\n",
    "#     723 여기를 수정하는거같은데\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"model_name.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: python-telegram-bot in /usr/local/lib/python3.6/dist-packages (13.7)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=6.1 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (6.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2018.6 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2021.1)\n",
      "Requirement already satisfied, skipping upgrade: cachetools==4.2.2 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (4.2.2)\n",
      "Requirement already satisfied, skipping upgrade: APScheduler==3.6.3 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (3.6.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (56.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tzlocal>=1.2 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (2.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: telepot in /usr/local/lib/python3.6/dist-packages (12.7)\n",
      "Requirement already satisfied: urllib3>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from telepot) (1.26.4)\n",
      "Requirement already satisfied: aiohttp>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from telepot) (3.7.4.post0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.0.0->telepot) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.0.0->telepot) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.0.0->telepot) (3.7.4.3)\n",
      "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.0.0->telepot) (1.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.0.0->telepot) (21.2.0)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.0.0->telepot) (4.0.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.0.0->telepot) (1.6.3)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from idna-ssl>=1.0; python_version < \"3.7\"->aiohttp>=3.0.0->telepot) (2.6)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-telegram-bot --upgrade\n",
    "!pip3 install telepot\n",
    "\n",
    "from telegram.ext import Updater, MessageHandler, Filters, CommandHandler\n",
    "import telegram\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-fde19713613f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;31m#message_handler3 = CommandHandler('menu1', get_command1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m \u001b[0mmessage_handler2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMessageHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_message' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from telegram.ext import Updater, MessageHandler, Filters, CommandHandler, CallbackQueryHandler # import modules\n",
    "from telegram import InlineKeyboardButton, InlineKeyboardMarkup\n",
    "my_token = '1702844077:AAHGt-dORzT8IMbDqBxLIx510IMkxVjoXN8'\n",
    "\n",
    "a=\"\"\n",
    "b=\"\"\n",
    "\n",
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "\n",
    "\n",
    "updater = Updater(my_token, use_context=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_message(update, context):\n",
    "    a=predict(update.message.text)\n",
    "\n",
    "    \n",
    "    update.message.reply_text(a)\n",
    "    output = predict(update.message.text)\n",
    "\n",
    "print(\"텔레그램 연결\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################\n",
    "def build_menu(buttons, n_cols, header_buttons=None, footer_buttons=None):\n",
    "    menu = [buttons[i:i + n_cols] for i in range(0, len(buttons), n_cols)]\n",
    "    if header_buttons:\n",
    "        menu.insert(0, header_buttons)\n",
    "    if footer_buttons:\n",
    "        menu.append(footer_buttons)\n",
    "    return menu\n",
    "\n",
    "def get_command(update, context):\n",
    "    print(\"get\")\n",
    "    show_list = []\n",
    "    show_list.append(InlineKeyboardButton(\"음식\", callback_data=\"음식\")) # add on button\n",
    "    show_list.append(InlineKeyboardButton(\"운동\", callback_data=\"운동\")) # add off button\n",
    "    show_list.append(InlineKeyboardButton(\"피팅\", callback_data=\"피팅\")) # add off button\n",
    "    \n",
    "    show_list.append(InlineKeyboardButton(\"나가기\", callback_data=\"나가기\")) # add cancel button\n",
    "    \n",
    "    show_markup = InlineKeyboardMarkup(build_menu(show_list, len(show_list) - 1)) # make markup\n",
    "\n",
    "    update.message.reply_text(\"메뉴를 선택하세요\", reply_markup=show_markup)\n",
    "\n",
    "# #################\n",
    "# def build_menu(buttons, n_cols, header_buttons=None, footer_buttons=None):\n",
    "#     menu = [buttons[i:i + n_cols] for i in range(0, len(buttons), n_cols)]\n",
    "#     if header_buttons:\n",
    "#         menu.insert(0, header_buttons)\n",
    "#     if footer_buttons:\n",
    "#         menu.append(footer_buttons)\n",
    "#     return menu\n",
    "\n",
    "# def get_command1(update, context):\n",
    "#     print(\"get\")\n",
    "#     show_list = []\n",
    "#     show_list.append(InlineKeyboardButton(\"칼로리 검색\", callback_data=\"칼로리 검색\")) # add on button\n",
    "#     show_list.append(InlineKeyboardButton(\"음식 사진 칼로리 검색\", callback_data=\"음식 사진 칼로리 검색\")) # add off button\n",
    "    \n",
    "#     show_list.append(InlineKeyboardButton(\"나가기\", callback_data=\"나가기\")) # add cancel button\n",
    "    \n",
    "#     show_markup = InlineKeyboardMarkup(build_menu(show_list, len(show_list) - 1)) # make markup\n",
    "\n",
    "#     update.message.reply_text(\"메뉴를 선택하세요\", reply_markup=show_markup)\n",
    "# #################\n",
    "def menu_1(update, context):\n",
    "    data_selected = update.callback_query.data\n",
    "    print(\"callback : \", data_selected) \n",
    "    if data_selected.find(\"나가기\") != -1 :\n",
    "        context.bot.edit_message_text(text=\"취소하였습니다.\",\n",
    "                                      chat_id=update.callback_query.message.chat_id,\n",
    "                                      message_id=update.callback_query.message.message_id)\n",
    "        return\n",
    "    \n",
    "    elif data_selected.find(\"음식\") != -1 :\n",
    "        context.bot.edit_message_text(text=\"음식 메뉴가 선택되었습니다.\",\n",
    "                                          chat_id=update.callback_query.message.chat_id,\n",
    "                                          message_id=update.callback_query.message.message_id)\n",
    "        \n",
    "        \n",
    "        return\n",
    "    elif data_selected.find(\"운동\") != -1 :\n",
    "        context.bot.edit_message_text(text=\"운동 메뉴가 선택되었습니다.\",\n",
    "                                          chat_id=update.callback_query.message.chat_id,\n",
    "                                          message_id=update.callback_query.message.message_id)\n",
    "        return\n",
    "    elif data_selected.find(\"피팅\") != -1 :\n",
    "        context.bot.edit_message_text(text=\"피팅 메뉴가 선택되었습니다.\",\n",
    "                                          chat_id=update.callback_query.message.chat_id,\n",
    "                                          message_id=update.callback_query.message.message_id)\n",
    "        return\n",
    "                                          \n",
    "\n",
    "def menu_1_1(update, context):\n",
    "    data_selected = update.callback_query.data\n",
    "    print(\"callback : \", data_selected)\n",
    "    if data_selected.find(\"칼로리 검색\") != -1 :\n",
    "        context.bot.edit_message_text(text=\"칼로리 검색 메뉴가 선택되었습니다.\",\n",
    "                                      chat_id=update.callback_query.message.chat_id,\n",
    "                                      message_id=update.callback_query.message.message_id)\n",
    "        return\n",
    "    \n",
    "    elif data_selected.find(\"음식 사진 칼로리 검색\") != -1 :\n",
    "        context.bot.edit_message_text(text=\"음식 사진 칼로리 검색 메뉴가 선택되었습니다.\",\n",
    "                                          chat_id=update.callback_query.message.chat_id,\n",
    "                                          message_id=update.callback_query.message.message_id)\n",
    "        return\n",
    "                                          \n",
    "                                          \n",
    "                                          \n",
    "                                          \n",
    "                                          \n",
    "\n",
    "message_handler1 = CommandHandler('menu', get_command)\n",
    "\n",
    "#message_handler3 = CommandHandler('menu1', get_command1)\n",
    "\n",
    "message_handler2 = MessageHandler(Filters.text, get_message)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "updater.dispatcher.add_handler(message_handler1)\n",
    "updater.dispatcher.add_handler(message_handler2)\n",
    "\n",
    "\n",
    "#updater.dispatcher.add_handler(message_handler3)\n",
    "\n",
    "####################\n",
    "\n",
    "updater.dispatcher.add_handler(CallbackQueryHandler(menu_1))\n",
    "updater.dispatcher.add_handler(CallbackQueryHandler(menu_1_1))\n",
    "\n",
    "####################\n",
    "\n",
    "\n",
    "updater.start_polling(timeout=3, drop_pending_updates=True)\n",
    "updater.idle()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
